{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Syifa Wanda Isnaini\n",
        "1103201248\n",
        "Machine Learning"
      ],
      "metadata": {
        "id": "__CJNYH1bfFu"
      }
    },
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSNK7duj5SeU"
      },
      "source": [
        "# 00. PyTorch Fundamentals\n",
        "\n",
        "## What is PyTorch?\n",
        "\n",
        "[PyTorch](https://pytorch.org/) is an open source machine learning and deep learning framework.\n",
        "\n",
        "## What can PyTorch be used for?\n",
        "\n",
        "PyTorch allows you to manipulate and process data and write machine learning algorithms using Python code.\n",
        "\n",
        "## Who uses PyTorch?\n",
        "\n",
        "Many of the worlds largest technology companies such as [Meta (Facebook)](https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/), Tesla and Microsoft as well as artificial intelligence research companies such as [OpenAI use PyTorch](https://openai.com/blog/openai-pytorch/) to power research and bring machine learning to their products.\n",
        "\n",
        "![pytorch being used across industry and research](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-being-used-across-research-and-industry.png)\n",
        "\n",
        "For example, Andrej Karpathy (head of AI at Tesla) has given several talks ([PyTorch DevCon 2019](https://youtu.be/oBklltKXtDE), [Tesla AI Day 2021](https://youtu.be/j0z4FweCy4M?t=2904)) about how Tesla use PyTorch to power their self-driving computer vision models.\n",
        "\n",
        "PyTorch is also used in other industries such as agriculture to [power computer vision on tractors](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1).\n",
        "\n",
        "## Why use PyTorch?\n",
        "\n",
        "Machine learning researchers love using PyTorch. And as of February 2022, PyTorch is the [most used deep learning framework on Papers With Code](https://paperswithcode.com/trends), a website for tracking machine learning research papers and the code repositories attached with them.\n",
        "\n",
        "PyTorch also helps take care of many things such as GPU acceleration (making your code run faster) behind the scenes.\n",
        "\n",
        "So you can focus on manipulating data and writing algorithms and PyTorch will make sure it runs fast.\n",
        "\n",
        "And if companies such as Tesla and Meta (Facebook) use it to build models they deploy to power hundreds of applications, drive thousands of cars and deliver content to billions of people, it's clearly capable on the development front too.\n",
        "\n",
        "## What we're going to cover in this module\n",
        "\n",
        "This course is broken down into different sections (notebooks).\n",
        "\n",
        "Each notebook covers important ideas and concepts within PyTorch.\n",
        "\n",
        "Subsequent notebooks build upon knowledge from the previous one (numbering starts at 00, 01, 02 and goes to whatever it ends up going to).\n",
        "\n",
        "This notebook deals with the basic building block of machine learning and deep learning, the tensor.\n",
        "\n",
        "Specifically, we're going to cover:\n",
        "\n",
        "| **Topic** | **Contents** |\n",
        "| ----- | ----- |\n",
        "| **Introduction to tensors** | Tensors are the basic building block of all of machine learning and deep learning. |\n",
        "| **Creating tensors** | Tensors can represent almost any kind of data (images, words, tables of numbers). |\n",
        "| **Getting information from tensors** | If you can put information into a tensor, you'll want to get it out too. |\n",
        "| **Manipulating tensors** | Machine learning algorithms (like neural networks) involve manipulating tensors in many different ways such as adding, multiplying, combining. |\n",
        "| **Dealing with tensor shapes** | One of the most common issues in machine learning is dealing with shape mismatches (trying to mixed wrong shaped tensors with other tensors). |\n",
        "| **Indexing on tensors** | If you've indexed on a Python list or NumPy array, it's very similar with tensors, except they can have far more dimensions. |\n",
        "| **Mixing PyTorch tensors and NumPy** | PyTorch plays with tensors ([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)), NumPy likes arrays ([`np.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)) sometimes you'll want to mix and match these. |\n",
        "| **Reproducibility** | Machine learning is very experimental and since it uses a lot of *randomness* to work, sometimes you'll want that *randomness* to not be so random. |\n",
        "| **Running tensors on GPU** | GPUs (Graphics Processing Units) make your code faster, PyTorch makes it easy to run your code on GPUs. |\n",
        "\n",
        "## Where can you get help?\n",
        "\n",
        "All of the materials for this course [live on GitHub](https://github.com/mrdbourke/pytorch-deep-learning).\n",
        "\n",
        "And if you run into trouble, you can ask a question on the [Discussions page](https://github.com/mrdbourke/pytorch-deep-learning/discussions) there too.\n",
        "\n",
        "There's also the [PyTorch developer forums](https://discuss.pytorch.org/), a very helpful place for all things PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v3iRCRUTGeu"
      },
      "source": [
        "## Importing PyTorch\n",
        "\n",
        "> **Note:** Before running any of the code in this notebook, you should have gone through the [PyTorch setup steps](https://pytorch.org/get-started/locally/).\n",
        ">\n",
        "> However, **if you're running on Google Colab**, everything should work (Google Colab comes with PyTorch and other libraries installed).\n",
        "\n",
        "Let's start by importing PyTorch and checking the version we're using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1VxEOik46Y4i",
        "outputId": "1fc11d57-9d81-4e36-c9b9-a1c6347fa0c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan modul PyTorch untuk mencetak versi PyTorch yang sedang digunakan. Berikut adalah penjelasan singkat:\n",
        "\n",
        "import torch: Ini mengimpor modul PyTorch ke dalam skrip atau lingkungan kerja Python Anda.\n",
        "\n",
        "torch.__version__: Ini adalah properti yang memberikan versi PyTorch yang sedang digunakan. Dengan menjalankan torch.__version__, Anda dapat melihat versi PyTorch yang terpasang pada sistem Anda.\n",
        "\n",
        "Anda dapat mengeksekusi kode ini untuk mendapatkan versi PyTorch yang sedang Anda gunakan dalam lingkungan Python Anda saat ini. Misalnya, hasilnya bisa seperti \"1.8.1\" atau versi lainnya, tergantung pada versi PyTorch yang Anda miliki diinstal."
      ],
      "metadata": {
        "id": "bG1tr_JU44CE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SqvI4S9TGew"
      },
      "source": [
        "Wonderful, it looks like we've got PyTorch 1.10.0+.\n",
        "\n",
        "This means if you're going through these materials, you'll see most compatability with PyTorch 1.10.0+, however if your version number is far higher than that, you might notice some inconsistencies.\n",
        "\n",
        "And if you do have any issues, please post on the course [GitHub Discussions page](https://github.com/mrdbourke/pytorch-deep-learning/discussions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-33BKR16iWc"
      },
      "source": [
        "## Introduction to tensors\n",
        "\n",
        "Now we've got PyTorch imported, it's time to learn about tensors.\n",
        "\n",
        "Tensors are the fundamental building block of machine learning.\n",
        "\n",
        "Their job is to represent data in a numerical way.\n",
        "\n",
        "For example, you could represent an image as a tensor with shape `[3, 224, 224]` which would mean `[colour_channels, height, width]`, as in the image has `3` colour channels (red, green, blue), a height of `224` pixels and a width of `224` pixels.\n",
        "\n",
        "![example of going from an input image to a tensor representation of the image, image gets broken down into 3 colour channels as well as numbers to represent the height and width](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)\n",
        "\n",
        "In tensor-speak (the language used to describe tensors), the tensor would have three dimensions, one for `colour_channels`, `height` and `width`.\n",
        "\n",
        "But we're getting ahead of ourselves.\n",
        "\n",
        "Let's learn more about tensors by coding them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFF0N2TU7S7Q"
      },
      "source": [
        "### Creating tensors\n",
        "\n",
        "PyTorch loves tensors. So much so there's a whole documentation page dedicated to the [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) class.\n",
        "\n",
        "Your first piece of homework is to [read through the documentation on `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) for 10-minutes. But you can get to that later.\n",
        "\n",
        "Let's code.\n",
        "\n",
        "The first thing we're going to create is a **scalar**.\n",
        "\n",
        "A scalar is a single number and in tensor-speak it's a zero dimension tensor.\n",
        "\n",
        "> **Note:** That's a trend for this course. We'll focus on writing specific code. But often I'll set exercises which involve reading and getting familiar with the PyTorch documentation. Because after all, once you're finished this course, you'll no doubt want to learn more. And the documentation is somewhere you'll be finding yourself quite often."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUDgG2zk7Us5",
        "outputId": "93ac3b1c-eabe-4ca7-f306-7b4504b2e287"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas membuat sebuah tensor skalar menggunakan PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.tensor(7): Membuat tensor skalar dengan nilai 7. Sebuah tensor skalar adalah tensor dengan hanya satu elemen atau nilai tunggal. Dalam konteks ini, tensor ini hanya berisi angka 7.\n",
        "\n",
        "scalar: Variabel yang menampung tensor skalar tersebut.\n",
        "\n",
        "scalar: Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor skalar. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi nilai skalar yang ditentukan, yaitu 7.\n",
        "\n",
        "Jadi, secara keseluruhan, kode ini mengilustrasikan cara membuat tensor skalar menggunakan PyTorch dan menyimpannya dalam variabel scalar."
      ],
      "metadata": {
        "id": "YpJOb5GJ5C7F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqSuhW7rTGey"
      },
      "source": [
        "See how the above printed out `tensor(7)`?\n",
        "\n",
        "That means although `scalar` is a single number, it's of type `torch.Tensor`.\n",
        "\n",
        "We can check the dimensions of a tensor using the `ndim` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV98Yz868bav",
        "outputId": "6bb70f8f-5d9f-4120-8ca9-e6de6ef40fc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam PyTorch, tensor skalar (tensor dengan hanya satu elemen) merupakan tensor 0 dimensi (dimensi nol). Kode scalar.ndim mencoba mengakses atribut ndim dari tensor scalar untuk mendapatkan jumlah dimensi tensor tersebut.\n",
        "\n",
        "Namun, tensor skalar dalam PyTorch tidak memiliki atribut ndim karena dimensinya adalah 0. Sebagai gantinya, kita dapat menggunakan metode dim() untuk mendapatkan jumlah dimensi dari tensor\n",
        "\n",
        "Dengan menggunakan dim(), kita dapat mengetahui bahwa tensor skalar memiliki 0 dimensi. Jadi, jika Anda menjalankan scalar.ndim, itu akan menghasilkan kesalahan karena atribut ndim tidak ditemukan pada tensor skalar dalam PyTorch."
      ],
      "metadata": {
        "id": "Y53rR16Y5Pzt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO2YW_QGTGez"
      },
      "source": [
        "What if we wanted to retrieve the number from the tensor?\n",
        "\n",
        "As in, turn it from `torch.Tensor` to a Python integer?\n",
        "\n",
        "To do we can use the `item()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k4cyKumPfbE",
        "outputId": "18553a81-9e90-4a4d-8346-203e7f120299"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Get the Python number within a tensor (only works with one-element tensors)\n",
        "scalar.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan metode .item() pada tensor skalar untuk mendapatkan nilai Python yang terkandung di dalam tensor tersebut. Berikut adalah penjelasan singkat:\n",
        "\n",
        "scalar: Ini adalah tensor skalar yang telah dibuat sebelumnya. Dalam contoh ini, diasumsikan bahwa scalar adalah tensor skalar yang berisi satu elemen.\n",
        "\n",
        ".item(): Metode ini digunakan untuk mengambil nilai Python dari tensor skalar. Dikarenakan tensor skalar hanya berisi satu elemen, metode ini dapat digunakan untuk mendapatkan nilai tersebut sebagai nilai Python biasa (int, float, dll.).\n",
        "\n",
        "Dalam hal ini, python_number akan berisi nilai Python 7, karena tensor skalar hanya memiliki satu elemen dan .item() digunakan untuk mengakses nilai tersebut dalam bentuk Python. Penting untuk dicatat bahwa .item() hanya berlaku untuk tensor dengan satu elemen. Jika tensor memiliki lebih dari satu elemen, penggunaan .item() akan menghasilkan kesalahan."
      ],
      "metadata": {
        "id": "d-5QU9MX50en"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYs7ulrATGe0"
      },
      "source": [
        "Okay, now let's see a **vector**.\n",
        "\n",
        "A vector is a single dimension tensor but can contain many numbers.\n",
        "\n",
        "As in, you could have a vector `[3, 2]` to describe `[bedrooms, bathrooms]` in your house. Or you could have `[3, 2, 2]` to describe `[bedrooms, bathrooms, car_parks]` in your house.\n",
        "\n",
        "The important trend here is that a vector is flexible in what it can represent (the same with tensors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IZF6ASs8QH9",
        "outputId": "6e758e5a-2737-49a6-ddbb-489b9c805a70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas membuat sebuah tensor vektor menggunakan PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.tensor([7, 7]): Membuat tensor vektor dengan dua elemen, yaitu 7 dan 7. Sebuah tensor vektor adalah tensor satu dimensi yang berisi sejumlah elemen.\n",
        "\n",
        "vector: Variabel yang menampung tensor vektor tersebut.\n",
        "\n",
        "vector: Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor vektor. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi nilai vektor yang ditentukan, yaitu [7, 7].\n",
        "\n",
        "Jadi, secara keseluruhan, kode ini mengilustrasikan cara membuat tensor vektor dengan dua elemen menggunakan PyTorch dan menyimpannya dalam variabel vector."
      ],
      "metadata": {
        "id": "0jQV0r9w6Hbz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXxRUUW2TGe1"
      },
      "source": [
        "Wonderful, `vector` now contains two 7's, my favourite number.\n",
        "\n",
        "How many dimensions do you think it'll have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03hm3VVv8kr4",
        "outputId": "c8dc93c7-0448-4b8d-9317-c3c67754dd76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Check the number of dimensions of vector\n",
        "vector.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam PyTorch, tensor vektor (tensor satu dimensi) memiliki satu dimensi. Kode vector.ndim mencoba untuk mengakses atribut ndim dari tensor vector untuk mendapatkan jumlah dimensi tensor tersebut.\n",
        "\n",
        "Namun, tensor vektor dalam PyTorch sebenarnya tidak memiliki atribut ndim, karena dimensinya sudah terdefinisi sebagai satu dimensi. Sebagai gantinya, kita dapat menggunakan metode dim() untuk mendapatkan jumlah dimensi dari tensor.\n",
        "\n",
        "Dengan menggunakan dim(), kita dapat mengetahui bahwa tensor vektor memiliki satu dimensi. Jadi, jika Anda menjalankan vector.ndim, itu mungkin menghasilkan kesalahan karena atribut ndim tidak ditemukan pada tensor vektor dalam PyTorch. Sebaiknya, gunakan metode dim() untuk mendapatkan jumlah dimensi."
      ],
      "metadata": {
        "id": "MfxgJpXS6M6I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0VYvSGbTGe1"
      },
      "source": [
        "Hmm, that's strange, `vector` contains two numbers but only has a single dimension.\n",
        "\n",
        "I'll let you in on a trick.\n",
        "\n",
        "You can tell the number of dimensions a tensor in PyTorch has by the number of square brackets on the outside (`[`) and you only need to count one side.\n",
        "\n",
        "How many square brackets does `vector` have?\n",
        "\n",
        "Another important concept for tensors is their `shape` attribute. The shape tells you how the elements inside them are arranged.\n",
        "\n",
        "Let's check out the shape of `vector`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zREV1bDTGe2",
        "outputId": "1f8e982b-b26c-4fba-fd37-148cb9b89bf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Check shape of vector\n",
        "vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk mendapatkan bentuk (shape) dari tensor dalam PyTorch, Anda dapat menggunakan atribut shape. Namun, perlu diingat bahwa untuk tensor satu dimensi seperti vektor, hasilnya akan disajikan dalam bentuk tupel dengan satu elemen.\n",
        "\n",
        "Output yang diharapkan dari kode ini adalah (2,). Ini menunjukkan bahwa vektor memiliki dua elemen dan merupakan tensor satu dimensi. Jadi, bentuknya adalah tupel dengan satu elemen yang menyatakan panjang vektor."
      ],
      "metadata": {
        "id": "qu-zSoxX6bqN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aWKppNyTGe2"
      },
      "source": [
        "The above returns `torch.Size([2])` which means our vector has a shape of `[2]`. This is because of the two elements we placed inside the square brackets (`[7, 7]`).\n",
        "\n",
        "Let's now see a **matrix**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5iNwCYL8QO9",
        "outputId": "fc8e3f60-0171-4c3e-b38c-a15fe7ed37dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Matrix\n",
        "MATRIX = torch.tensor([[7, 8],\n",
        "                       [9, 10]])\n",
        "MATRIX"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas membuat sebuah tensor matriks menggunakan PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.tensor([[7, 8], [9, 10]]): Membuat tensor matriks dengan dua baris dan dua kolom. Sebuah tensor matriks adalah tensor dua dimensi yang berisi elemen-elemen ini.\n",
        "\n",
        "MATRIX: Variabel yang menampung tensor matriks tersebut.\n",
        "\n",
        "MATRIX: Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor matriks. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi nilai matriks yang ditentukan.\n",
        "\n",
        "Jadi, secara keseluruhan, kode ini mengilustrasikan cara membuat tensor matriks dengan elemen-elemen tertentu menggunakan PyTorch dan menyimpannya dalam variabel MATRIX."
      ],
      "metadata": {
        "id": "CNxv078Y6lGk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3U1bCdjTGe3"
      },
      "source": [
        "Wow! More numbers! Matrices are as flexible as vectors, except they've got an extra dimension.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LREUbeb8r8j",
        "outputId": "44bc84e2-d813-4c60-e451-c20eebcd9986"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Check number of dimensions\n",
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk mendapatkan jumlah dimensi dari tensor dalam PyTorch, Anda dapat menggunakan metode dim() atau properti ndim. Namun, perlu diingat bahwa matriks adalah tensor dua dimensi.\n",
        "\n",
        "Hasil dari MATRIX.dim() adalah 2, yang menunjukkan bahwa matriks memiliki dua dimensi. Jika Anda ingin menggunakan ndim, Anda dapat menggantinya dengan MATRIX.ndim, dan itu juga akan menghasilkan 2."
      ],
      "metadata": {
        "id": "2au7NDbE6rlb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhXXgq-dTGe3"
      },
      "source": [
        "`MATRIX` has two dimensions (did you count the number of square brakcets on the outside of one side?).\n",
        "\n",
        "What `shape` do you think it will have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TL26I31TGe3",
        "outputId": "ddc22be4-e171-47a5-ca1c-6f90c1c8151c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "MATRIX.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode MATRIX.shape bertujuan untuk menampilkan bentuk (shape) dari suatu tensor matriks yang disimpan dalam variabel MATRIX. Berikut adalah penjelasan singkat:\n",
        "\n",
        "MATRIX: Ini adalah variabel yang mengacu pada suatu tensor matriks PyTorch yang sudah didefinisikan sebelumnya.\n",
        "\n",
        ".shape: Atribut ini digunakan untuk mendapatkan bentuk (shape) dari tensor. Bentuk tensor mencakup informasi tentang jumlah dimensi dan ukuran masing-masing dimensi.\n",
        "\n",
        "MATRIX.shape: Eksekusi perintah ini akan mengembalikan bentuk tensor yang diakses melalui atribut shape. Outputnya berupa tupel yang menyatakan jumlah elemen dalam setiap dimensi.\n",
        "\n",
        "Contoh output bisa berupa (2, 2), yang berarti matriks tersebut memiliki dua dimensi dengan dua elemen dalam setiap dimensinya. Pastikan bahwa variabel MATRIX telah didefinisikan sebagai tensor matriks PyTorch sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "H5nW0yDK7kyT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvLpUvrKTGe4"
      },
      "source": [
        "We get the output `torch.Size([2, 2])` because `MATRIX` is two elements deep and two elements wide.\n",
        "\n",
        "How about we create a **tensor**?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEMDQr188QWW",
        "outputId": "e4033172-5d07-4471-d957-19b5bdd4a1b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [2, 4, 5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Tensor\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]])\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan sebuah tensor tiga dimensi menggunakan PyTorch dan kemudian menampilkan nilai tensor tersebut. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.tensor([[[1, 2, 3], [3, 6, 9], [2, 4, 5]]]): Membuat tensor tiga dimensi dengan nilai yang diberikan. Dalam hal ini, tensor tersebut memiliki tiga dimensi: satu dimensi untuk \"tumpukan\" lapisan, satu dimensi untuk baris, dan satu dimensi untuk kolom.\n",
        "\n",
        "TENSOR: Variabel yang menampung tensor tiga dimensi yang baru dibuat.\n",
        "\n",
        "TENSOR: Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor tersebut. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi nilai tensor tiga dimensi yang ditentukan.\n",
        "Ini menunjukkan bahwa tensor tersebut memiliki tiga dimensi, dengan ukuran masing-masing dimensinya adalah 1, 3, dan 3. Pastikan bahwa variabel TENSOR telah didefinisikan sebagai tensor PyTorch sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "wuRWFgiF7sfj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmJKkXD7TGe4"
      },
      "source": [
        "Woah! What a nice looking tensor.\n",
        "\n",
        "I want to stress that tensors can represent almost anything.\n",
        "\n",
        "The one we just created could be the sales numbers for a steak and almond butter store (two of my favourite foods).\n",
        "\n",
        "![a simple tensor in google sheets showing day of week, steak sales and almond butter sales](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_simple_tensor.png)\n",
        "\n",
        "How many dimensions do you think it has? (hint: use the square bracket counting trick)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dhuEsjS8QcT",
        "outputId": "7541cd3d-7987-45d0-9794-0d2b7fe37b08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Check number of dimensions for TENSOR\n",
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode TENSOR.ndim mencoba untuk mengecek jumlah dimensi dari tensor yang disimpan dalam variabel TENSOR menggunakan properti ndim. Namun, perlu dicatat bahwa properti ndim tidak langsung tersedia pada objek tensor di PyTorch.\n",
        "\n",
        "Dalam PyTorch, untuk mendapatkan jumlah dimensi dari suatu tensor, Anda dapat menggunakan metode dim() atau properti ndim.\n",
        "\n",
        "Hasil dari TENSOR.dim() adalah 3, yang menunjukkan bahwa tensor tersebut memiliki tiga dimensi. Properti ndim tidak umum digunakan dalam konteks PyTorch, jadi sebaiknya menggunakan metode dim() untuk memeriksa jumlah dimensi dari suatu tensor."
      ],
      "metadata": {
        "id": "OyyH81_u72L1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln9dys5VTGe4"
      },
      "source": [
        "And what about its shape?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdVv4iNRTGe5",
        "outputId": "0e6b2738-b6ca-4b71-be61-d2cac84a4825"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Check shape of TENSOR\n",
        "TENSOR.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas bertujuan untuk menampilkan bentuk (shape) dari suatu tensor yang disimpan dalam variabel TENSOR menggunakan atribut shape. Berikut adalah penjelasan singkat:\n",
        "\n",
        "TENSOR: Ini adalah variabel yang mengacu pada suatu tensor PyTorch yang sudah didefinisikan sebelumnya.\n",
        "\n",
        ".shape: Atribut ini digunakan untuk mendapatkan bentuk (shape) dari tensor. Bentuk tensor mencakup informasi tentang jumlah dimensi dan ukuran masing-masing dimensi.\n",
        "\n",
        "TENSOR.shape: Eksekusi perintah ini akan mengembalikan bentuk tensor yang diakses melalui atribut shape. Outputnya berupa tupel yang menyatakan jumlah elemen dalam setiap dimensi.\n",
        "\n",
        "Contoh output bisa berupa (2, 3), yang berarti tensor tersebut memiliki dua dimensi dengan dua elemen dalam dimensi pertama dan tiga elemen dalam dimensi kedua. Pastikan bahwa variabel TENSOR telah didefinisikan sebagai tensor PyTorch sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "UTuugTdS7UAH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxk8GU7oTGe5"
      },
      "source": [
        "Alright, it outputs `torch.Size([1, 3, 3])`.\n",
        "\n",
        "The dimensions go outer to inner.\n",
        "\n",
        "That means there's 1 dimension of 3 by 3.\n",
        "\n",
        "![example of different tensor dimensions](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)\n",
        "\n",
        "> **Note:** You might've noticed me using lowercase letters for `scalar` and `vector` and uppercase letters for `MATRIX` and `TENSOR`. This was on purpose. In practice, you'll often see scalars and vectors denoted as lowercase letters such as `y` or `a`. And matrices and tensors denoted as uppercase letters such as `X` or `W`.\n",
        ">\n",
        "> You also might notice the names martrix and tensor used interchangably. This is common. Since in PyTorch you're often dealing with `torch.Tensor`s (hence the tensor name), however, the shape and dimensions of what's inside will dictate what it actually is.\n",
        "\n",
        "Let's summarise.\n",
        "\n",
        "| Name | What is it? | Number of dimensions | Lower or upper (usually/example) |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| **scalar** | a single number | 0 | Lower (`a`) |\n",
        "| **vector** | a number with direction (e.g. wind speed with direction) but can also have many other numbers | 1 | Lower (`y`) |\n",
        "| **matrix** | a 2-dimensional array of numbers | 2 | Upper (`Q`) |\n",
        "| **tensor** | an n-dimensional array of numbers | can be any number, a 0-dimension tensor is a scalar, a 1-dimension tensor is a vector | Upper (`X`) |\n",
        "\n",
        "![scalar vector matrix tensor and what they look like](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dms7G4nkTGe5"
      },
      "source": [
        "### Random tensors\n",
        "\n",
        "We've established tensors represent some form of data.\n",
        "\n",
        "And machine learning models such as neural networks manipulate and seek patterns within tensors.\n",
        "\n",
        "But when building machine learning models with PyTorch, it's rare you'll create tensors by hand (like what we've being doing).\n",
        "\n",
        "Instead, a machine learning model often starts out with large random tensors of numbers and adjusts these random numbers as it works through data to better represent it.\n",
        "\n",
        "In essence:\n",
        "\n",
        "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...`\n",
        "\n",
        "As a data scientist, you can define how the machine learning model starts (initialization), looks at data (representation) and updates (optimization) its random numbers.\n",
        "\n",
        "We'll get hands on with these steps later on.\n",
        "\n",
        "For now, let's see how to create a tensor of random numbers.\n",
        "\n",
        "We can do so using [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) and passing in the `size` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOJEtDx--GnK",
        "outputId": "8b3f296f-3392-4107-9111-e1702a8ff4ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.7536, 0.2423, 0.4965, 0.7845],\n",
              "         [0.1123, 0.5882, 0.4545, 0.8213],\n",
              "         [0.0595, 0.7554, 0.7247, 0.9639]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Create a random tensor of size (3, 4)\n",
        "random_tensor = torch.rand(size=(3, 4))\n",
        "random_tensor, random_tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Kode di atas menciptakan sebuah tensor acak dengan ukuran (3, 4) menggunakan PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.rand(size=(3, 4)): Membuat tensor acak dengan ukuran (3, 4). Fungsi torch.rand() menghasilkan tensor dengan nilai acak yang terdistribusi seragam antara 0 dan 1. Parameter size digunakan untuk menentukan ukuran tensor yang diinginkan.\n",
        "\n",
        "random_tensor: Variabel yang menampung tensor acak yang baru dibuat.\n",
        "\n",
        "random_tensor.dtype: Mengakses properti dtype dari tensor untuk mendapatkan tipe data (dtype) tensor tersebut. Properti ini memberikan informasi tentang tipe data elemen dalam tensor.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor acak dan tipe datanya. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi nilai-nilai acak dan tipe data tensor tersebut.\n",
        "\n",
        "Ini menunjukkan tensor acak dengan ukuran (3, 4) dan tipe data elemen float32. Pastikan bahwa variabel random_tensor telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "uIl2mdHA8Di2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wB1c_cXTGe5"
      },
      "source": [
        "The flexibility of `torch.rand()` is that we can adjust the `size` to be whatever we want.\n",
        "\n",
        "For example, say you wanted a random tensor in the common image shape of `[224, 224, 3]` (`[height, width, color_channels`])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMF_NUp3Ym__",
        "outputId": "21caaac0-8fc6-4115-908a-957d9c3bfdac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Create a random tensor of size (224, 224, 3)\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan sebuah tensor acak dengan ukuran (224, 224, 3) menggunakan PyTorch. Namun, perlu dicatat bahwa hal ini dapat menyebabkan masalah karena ukuran ini tidak sesuai dengan konvensi untuk representasi gambar dalam bentuk tensor.\n",
        "\n",
        "Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.rand(size=(224, 224, 3)): Membuat tensor acak dengan ukuran (224, 224, 3). Fungsi torch.rand() menghasilkan tensor dengan nilai acak yang terdistribusi seragam antara 0 dan 1. Parameter size digunakan untuk menentukan ukuran tensor yang diinginkan.\n",
        "\n",
        "random_image_size_tensor: Variabel yang menampung tensor acak yang baru dibuat.\n",
        "\n",
        "random_image_size_tensor.shape: Mengakses atribut shape dari tensor untuk mendapatkan bentuk (shape) tensor tersebut. Bentuk tensor memberikan informasi tentang jumlah dimensi dan ukuran masing-masing dimensi.\n",
        "\n",
        "random_image_size_tensor.ndim: Mengakses metode ndim dari tensor untuk mendapatkan jumlah dimensi tensor tersebut.\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan bentuk dan jumlah dimensi tensor. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi bentuk dan jumlah dimensi tensor tersebut.\n",
        "\n",
        "Perlu dicatat bahwa ukuran (224, 224, 3) tidak sesuai dengan representasi gambar yang umum digunakan dalam machine learning, di mana gambar biasanya diwakili sebagai tensor dengan dimensi (batch_size, channels, height, width). Jika Anda ingin menciptakan tensor gambar dengan ukuran (224, 224, 3), sebaiknya gunakan dimensi yang benar, misalnya, (1, 3, 224, 224) jika ini adalah satu gambar."
      ],
      "metadata": {
        "id": "ZT8f4dw48RQ4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MQNTY0eTGe6"
      },
      "source": [
        "### Zeros and ones\n",
        "\n",
        "Sometimes you'll just want to fill tensors with zeros or ones.\n",
        "\n",
        "This happens a lot with masking (like masking some of the values in one tensor with zeros to let a model know not to learn them).\n",
        "\n",
        "Let's create a tensor full of zeros with [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html)\n",
        "\n",
        "Again, the `size` parameter comes into play."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCzhd0hl9Vp6",
        "outputId": "0dfde2d8-6887-4a14-9b23-b45c1555a477"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Create a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros, zeros.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan sebuah tensor dengan semua elemen bernilai nol, menggunakan PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.zeros(size=(3, 4)): Membuat tensor dengan semua elemen bernilai nol dan ukuran (shape) (3, 4). Fungsi torch.zeros() menghasilkan tensor dengan elemen-elemen nol. Parameter size digunakan untuk menentukan ukuran tensor yang diinginkan.\n",
        "\n",
        "zeros: Variabel yang menampung tensor nol yang baru dibuat.\n",
        "\n",
        "zeros.dtype: Mengakses properti dtype dari tensor untuk mendapatkan tipe data (dtype) tensor tersebut. Properti ini memberikan informasi tentang tipe data elemen dalam tensor.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor nol dan tipe datanya. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi tensor dengan elemen-elemen nol dan tipe data tensor tersebut.\n",
        "Ini menunjukkan tensor dengan ukuran (3, 4) yang terdiri dari elemen-elemen nol dan memiliki tipe data elemen float32. Pastikan bahwa variabel zeros telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "5ygUMzzT8cnN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDQBZJRUZWTN"
      },
      "source": [
        "We can do the same to create a tensor of all ones except using [`torch.ones()` ](https://pytorch.org/docs/stable/generated/torch.ones.html) instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRe6sSXiTGe6",
        "outputId": "28b5259a-07c9-4b1c-f3fb-44d6ef30fc9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Create a tensor of all ones\n",
        "ones = torch.ones(size=(3, 4))\n",
        "ones, ones.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan sebuah tensor dengan semua elemen bernilai satu, menggunakan PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.ones(size=(3, 4)): Membuat tensor dengan semua elemen bernilai satu dan ukuran (shape) (3, 4). Fungsi torch.ones() menghasilkan tensor dengan elemen-elemen satu. Parameter size digunakan untuk menentukan ukuran tensor yang diinginkan.\n",
        "\n",
        "ones: Variabel yang menampung tensor satu yang baru dibuat.\n",
        "\n",
        "ones.dtype: Mengakses properti dtype dari tensor untuk mendapatkan tipe data (dtype) tensor tersebut. Properti ini memberikan informasi tentang tipe data elemen dalam tensor.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor satu dan tipe datanya. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi tensor dengan elemen-elemen satu dan tipe data tensor tersebut.\n",
        "Ini menunjukkan tensor dengan ukuran (3, 4) yang terdiri dari elemen-elemen satu dan memiliki tipe data elemen float32. Pastikan bahwa variabel ones telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "EC26s2Zh8o01"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hib1NYrSarL2"
      },
      "source": [
        "### Creating a range and tensors like\n",
        "\n",
        "Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100.\n",
        "\n",
        "You can use `torch.arange(start, end, step)` to do so.\n",
        "\n",
        "Where:\n",
        "* `start` = start of range (e.g. 0)\n",
        "* `end` = end of range (e.g. 10)\n",
        "* `step` = how many steps in between each value (e.g. 1)\n",
        "\n",
        "> **Note:** In Python, you can use `range()` to create a range. However in PyTorch, `torch.range()` is deprecated and may show an error in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IqUs81d9W4W",
        "outputId": "e32acef4-3bef-4769-caf8-4a584ed35113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a09072c806d9>:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Use torch.arange(), torch.range() is deprecated\n",
        "zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n",
        "\n",
        "# Create a range of values 0 to 10\n",
        "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
        "zero_to_ten"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Kode di atas menciptakan tensor yang berisi rentang nilai dari 0 hingga 9 menggunakan dua metode berbeda: torch.range() yang sudah tidak direkomendasikan (deprecated) dan torch.arange(). Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.range(0, 10): Metode ini sebelumnya digunakan untuk membuat tensor yang berisi rentang nilai dari 0 hingga 10, namun metode ini sudah tidak direkomendasikan (deprecated). Catatan: ini mungkin menghasilkan kesalahan di masa depan karena telah di-deprecate.\n",
        "\n",
        "torch.arange(start=0, end=10, step=1): Metode ini lebih disarankan untuk membuat tensor yang berisi rentang nilai. torch.arange() memungkinkan Anda menentukan nilai awal (start), nilai akhir (end), dan langkah (step) untuk membuat rentang nilai.\n",
        "\n",
        "zero_to_ten: Variabel yang menampung tensor yang baru dibuat menggunakan torch.arange().\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor yang berisi rentang nilai dari 0 hingga 9.\n",
        "Dalam hal ini, zero_to_ten akan berisi tensor dengan nilai-nilai yang membentuk rentang dari 0 hingga 9 (tidak termasuk 10) dengan langkah 1. Pastikan bahwa Anda menggunakan torch.arange() sebagai pengganti torch.range() yang sudah di-deprecate."
      ],
      "metadata": {
        "id": "-MEieQMT8yyp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-bXf0Ugbh-D"
      },
      "source": [
        "Sometimes you might want one tensor of a certain type with the same shape as another tensor.\n",
        "\n",
        "For example, a tensor of all zeros with the same shape as a previous tensor.\n",
        "\n",
        "To do so you can use [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) which return a tensor filled with zeros or ones in the same shape as the `input` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvXwUut5BhHq",
        "outputId": "6eed0393-9535-430b-d756-ee1570c6002d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Can also create a tensor of zeros similar to another tensor\n",
        "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan sebuah tensor yang berisi nol dan memiliki bentuk (shape) yang sama dengan tensor lain (zero_to_ten). Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.zeros_like(input=zero_to_ten): Metode ini membuat tensor dengan elemen-elemen nol dan bentuk yang sama dengan tensor yang diberikan sebagai argumen (dalam hal ini, zero_to_ten). Fungsi ini memungkinkan pembuatan tensor dengan nol yang memiliki bentuk yang sesuai dengan tensor referensi.\n",
        "\n",
        "ten_zeros: Variabel yang menampung tensor nol yang baru dibuat, dengan bentuk yang sama seperti tensor zero_to_ten.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor yang berisi elemen-elemen nol dan memiliki bentuk yang sama dengan tensor referensi (zero_to_ten).\n",
        "\n",
        "Contoh output yang diharapkan dari ten_zeros akan memiliki bentuk yang sama seperti zero_to_ten dan elemen-elemen berisi nol\n",
        "Ini menunjukkan tensor dengan bentuk yang sesuai dengan zero_to_ten dan elemen-elemen yang semuanya nol. Pastikan bahwa variabel zero_to_ten telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "IhYN_W158-fW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huKZ6QlYTGe7"
      },
      "source": [
        "### Tensor datatypes\n",
        "\n",
        "There are many different [tensor datatypes available in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
        "\n",
        "Some are specific for CPU and some are better for GPU.\n",
        "\n",
        "Getting to know which is which can take some time.\n",
        "\n",
        "Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
        "\n",
        "The most common type (and generally the default) is `torch.float32` or `torch.float`.\n",
        "\n",
        "This is referred to as \"32-bit floating point\".\n",
        "\n",
        "But there's also 16-bit floating point (`torch.float16` or `torch.half`) and 64-bit floating point (`torch.float64` or `torch.double`).\n",
        "\n",
        "And to confuse things even more there's also 8-bit, 16-bit, 32-bit and 64-bit integers.\n",
        "\n",
        "Plus more!\n",
        "\n",
        "> **Note:** An integer is a flat round number like `7` whereas a float has a decimal `7.0`.\n",
        "\n",
        "The reason for all of these is to do with **precision in computing**.\n",
        "\n",
        "Precision is the amount of detail used to describe a number.\n",
        "\n",
        "The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
        "\n",
        "This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
        "\n",
        "So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).\n",
        "\n",
        "> **Resources:**\n",
        "  * See the [PyTorch documentation for a list of all available tensor datatypes](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
        "  * Read the [Wikipedia page for an overview of what precision in computing](https://en.wikipedia.org/wiki/Precision_(computer_science)) is.\n",
        "\n",
        "Let's see how to create some tensors with specific datatypes. We can do so using the `dtype` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3MoGnpw9XaF",
        "outputId": "1187984d-307d-4d96-bb49-489e958dae45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Default datatype for tensors is float32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
        "                               device=None, # defaults to None, which uses the default tensor type\n",
        "                               requires_grad=False) # if True, operations performed on the tensor are recorded\n",
        "\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "User\n",
        "# Shapes need to be in the right way  \n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "torch.matmul(tensor_A, tensor_B) # (this will error)\n",
        "perbaiki error pada kode diatas dengan error\n",
        "RuntimeError                              Traceback (most recent call last)\n",
        "<ipython-input-38-aceec990e652> in <cell line: 10>()\n",
        "      8                          [9, 12]], dtype=torch.float32)\n",
        "      9\n",
        "---> 10 torch.matmul(tensor_A, tensor_B) # (this will error)\n",
        "\n",
        "RuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\n",
        "ChatGPT\n",
        "Error ini muncul karena ketidakcocokan bentuk (shape) tensor yang dioperasikan oleh fungsi torch.matmul. Untuk mengatasi error ini, kita perlu mengubah bentuk salah satu tensor sehingga memenuhi persyaratan perkalian matriks.\n",
        "\n",
        "Berikut adalah cara memperbaiki error tersebut dengan mengubah bentuk tensor_B menjadi matriks transpose:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import torch\n",
        "\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "# Transpose tensor_B to make the matrix multiplication valid\n",
        "tensor_B_transposed = torch.transpose(tensor_B, 0, 1)\n",
        "\n",
        "result = torch.matmul(tensor_A, tensor_B_transposed)\n",
        "\n",
        "print(result)\n",
        "Dengan melakukan transposisi tensor_B menggunakan torch.transpose(tensor_B, 0, 1), kita mengubah bentuk tensor_B dari (3x2) menjadi (2x3), sehingga dapat dioperasikan dengan tensor_A yang memiliki bentuk (3x2).\n",
        "\n",
        "User\n",
        "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
        "tensor_on_gpu.numpy()\n",
        "perbaiki kode diatas dengan error\n",
        "TypeError                                 Traceback (most recent call last)\n",
        "<ipython-input-77-53175578f49e> in <cell line: 2>()\n",
        "      1 # If tensor is on GPU, can't transform it to NumPy (this will error)\n",
        "----> 2 tensor_on_gpu.numpy()\n",
        "\n",
        "TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
        "ChatGPT\n",
        "Error tersebut terjadi karena Anda mencoba mengonversi tensor yang berada di GPU (cuda:0) langsung menjadi NumPy array. Untuk memperbaiki ini, Anda perlu memindahkan tensor dari GPU ke CPU terlebih dahulu, dan baru kemudian mengonversikannya menjadi NumPy array.\n",
        "\n",
        "Berikut adalah cara memperbaiki kodenya:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import torch\n",
        "\n",
        "# Contoh tensor di GPU\n",
        "tensor_on_gpu = torch.tensor([1, 2, 3], device='cuda:0')\n",
        "\n",
        "# Memindahkan tensor dari GPU ke CPU\n",
        "tensor_on_cpu = tensor_on_gpu.cpu()\n",
        "\n",
        "# Mengonversi tensor yang berada di CPU menjadi NumPy array\n",
        "numpy_array = tensor_on_cpu.numpy()\n",
        "\n",
        "print(numpy_array)\n",
        "Dalam contoh di atas, cpu() digunakan untuk memindahkan tensor dari GPU ke CPU, dan setelah itu, Anda dapat menggunakan numpy() untuk mengonversikannya menjadi NumPy array.\n",
        "\n",
        "User\n",
        "import torch\n",
        "torch.__version__\n",
        "berikan penjelasan mengenai kode diatas\n",
        "ChatGPT\n",
        "Kode di atas menggunakan modul PyTorch untuk mencetak versi PyTorch yang sedang digunakan. Berikut adalah penjelasan singkat:\n",
        "\n",
        "import torch: Ini mengimpor modul PyTorch ke dalam skrip atau lingkungan kerja Python Anda.\n",
        "\n",
        "torch.__version__: Ini adalah properti yang memberikan versi PyTorch yang sedang digunakan. Dengan menjalankan torch.__version__, Anda dapat melihat versi PyTorch yang terpasang pada sistem Anda.\n",
        "\n",
        "Anda dapat mengeksekusi kode ini untuk mendapatkan versi PyTorch yang sedang Anda gunakan dalam lingkungan Python Anda saat ini. Misalnya, hasilnya bisa seperti \"1.8.1\" atau versi lainnya, tergantung pada versi PyTorch yang Anda miliki diinstal.\n",
        "\n",
        "User\n",
        "# Scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar\n",
        "Berikan penjelasan dari kode diatas\n",
        "ChatGPT\n",
        "Kode di atas membuat sebuah tensor skalar menggunakan PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.tensor(7): Membuat tensor skalar dengan nilai 7. Sebuah tensor skalar adalah tensor dengan hanya satu elemen atau nilai tunggal. Dalam konteks ini, tensor ini hanya berisi angka 7.\n",
        "\n",
        "scalar: Variabel yang menampung tensor skalar tersebut.\n",
        "\n",
        "scalar: Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor skalar. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi nilai skalar yang ditentukan, yaitu 7.\n",
        "\n",
        "Jadi, secara keseluruhan, kode ini mengilustrasikan cara membuat tensor skalar menggunakan PyTorch dan menyimpannya dalam variabel scalar.\n",
        "\n",
        "User\n",
        "scalar.ndim\n",
        "berikan penjelasan dari kode diatas\n",
        "ChatGPT\n",
        "Dalam PyTorch, tensor skalar (tensor dengan hanya satu elemen) merupakan tensor 0 dimensi (dimensi nol). Kode scalar.ndim mencoba mengakses atribut ndim dari tensor scalar untuk mendapatkan jumlah dimensi tensor tersebut.\n",
        "\n",
        "Namun, tensor skalar dalam PyTorch tidak memiliki atribut ndim karena dimensinya adalah 0. Sebagai gantinya, kita dapat menggunakan metode dim() untuk mendapatkan jumlah dimensi dari tensor. Contoh:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "scalar = torch.tensor(7)\n",
        "print(scalar.dim())  # Output: 0\n",
        "Dengan menggunakan dim(), kita dapat mengetahui bahwa tensor skalar memiliki 0 dimensi. Jadi, jika Anda menjalankan scalar.ndim, itu akan menghasilkan kesalahan karena atribut ndim tidak ditemukan pada tensor skalar dalam PyTorch.\n",
        "\n",
        "User\n",
        "# Get the Python number within a tensor (only works with one-element tensors)\n",
        "scalar.item()\n",
        "berikan penjelasan dari kode diatas\n",
        "ChatGPT\n",
        "Kode di atas menggunakan metode .item() pada tensor skalar untuk mendapatkan nilai Python yang terkandung di dalam tensor tersebut. Berikut adalah penjelasan singkat:\n",
        "\n",
        "scalar: Ini adalah tensor skalar yang telah dibuat sebelumnya. Dalam contoh ini, diasumsikan bahwa scalar adalah tensor skalar yang berisi satu elemen.\n",
        "\n",
        ".item(): Metode ini digunakan untuk mengambil nilai Python dari tensor skalar. Dikarenakan tensor skalar hanya berisi satu elemen, metode ini dapat digunakan untuk mendapatkan nilai tersebut sebagai nilai Python biasa (int, float, dll.).\n",
        "\n",
        "Contoh penggunaan:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "scalar = torch.tensor(7)\n",
        "python_number = scalar.item()\n",
        "print(python_number)\n",
        "Dalam hal ini, python_number akan berisi nilai Python 7, karena tensor skalar hanya memiliki satu elemen dan .item() digunakan untuk mengakses nilai tersebut dalam bentuk Python. Penting untuk dicatat bahwa .item() hanya berlaku untuk tensor dengan satu elemen. Jika tensor memiliki lebih dari satu elemen, penggunaan .item() akan menghasilkan kesalahan.\n",
        "\n",
        "User\n",
        "# Vector\n",
        "vector = torch.tensor([7, 7])\n",
        "vector\n",
        "berikan penjelasan dari kode diatas\n",
        "ChatGPT\n",
        "Kode di atas membuat sebuah tensor vektor menggunakan PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.tensor([7, 7]): Membuat tensor vektor dengan dua elemen, yaitu 7 dan 7. Sebuah tensor vektor adalah tensor satu dimensi yang berisi sejumlah elemen.\n",
        "\n",
        "vector: Variabel yang menampung tensor vektor tersebut.\n",
        "\n",
        "vector: Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor vektor. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi nilai vektor yang ditentukan, yaitu [7, 7].\n",
        "\n",
        "Jadi, secara keseluruhan, kode ini mengilustrasikan cara membuat tensor vektor dengan dua elemen menggunakan PyTorch dan menyimpannya dalam variabel vector.\n",
        "\n",
        "User\n",
        "# Check the number of dimensions of vector\n",
        "vector.ndim\n",
        "ChatGPT\n",
        "Dalam PyTorch, tensor vektor (tensor satu dimensi) memiliki satu dimensi. Kode vector.ndim mencoba untuk mengakses atribut ndim dari tensor vector untuk mendapatkan jumlah dimensi tensor tersebut.\n",
        "\n",
        "Namun, tensor vektor dalam PyTorch sebenarnya tidak memiliki atribut ndim, karena dimensinya sudah terdefinisi sebagai satu dimensi. Sebagai gantinya, kita dapat menggunakan metode dim() untuk mendapatkan jumlah dimensi dari tensor. Contoh:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "vector = torch.tensor([7, 7])\n",
        "print(vector.dim())  # Output: 1\n",
        "Dengan menggunakan dim(), kita dapat mengetahui bahwa tensor vektor memiliki satu dimensi. Jadi, jika Anda menjalankan vector.ndim, itu mungkin menghasilkan kesalahan karena atribut ndim tidak ditemukan pada tensor vektor dalam PyTorch. Sebaiknya, gunakan metode dim() untuk mendapatkan jumlah dimensi.\n",
        "\n",
        "User\n",
        "# Check shape of vector\n",
        "vector.shape\n",
        "ChatGPT\n",
        "Untuk mendapatkan bentuk (shape) dari tensor dalam PyTorch, Anda dapat menggunakan atribut shape. Namun, perlu diingat bahwa untuk tensor satu dimensi seperti vektor, hasilnya akan disajikan dalam bentuk tupel dengan satu elemen.\n",
        "\n",
        "Berikut adalah contoh penggunaan untuk mendapatkan bentuk dari tensor vektor:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import torch\n",
        "\n",
        "vector = torch.tensor([7, 7])\n",
        "print(vector.shape)\n",
        "Output yang diharapkan dari kode ini adalah (2,). Ini menunjukkan bahwa vektor memiliki dua elemen dan merupakan tensor satu dimensi. Jadi, bentuknya adalah tupel dengan satu elemen yang menyatakan panjang vektor.\n",
        "\n",
        "\n",
        "2 / 2\n",
        "\n",
        "User\n",
        "# Matrix\n",
        "MATRIX = torch.tensor([[7, 8],\n",
        "                       [9, 10]])\n",
        "MATRIX\n",
        "ChatGPT\n",
        "Kode di atas membuat sebuah tensor matriks menggunakan PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.tensor([[7, 8], [9, 10]]): Membuat tensor matriks dengan dua baris dan dua kolom. Sebuah tensor matriks adalah tensor dua dimensi yang berisi elemen-elemen ini.\n",
        "\n",
        "MATRIX: Variabel yang menampung tensor matriks tersebut.\n",
        "\n",
        "MATRIX: Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor matriks. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi nilai matriks yang ditentukan.\n",
        "\n",
        "Jadi, secara keseluruhan, kode ini mengilustrasikan cara membuat tensor matriks dengan elemen-elemen tertentu menggunakan PyTorch dan menyimpannya dalam variabel MATRIX.\n",
        "\n",
        "User\n",
        "# Check number of dimensions\n",
        "MATRIX.ndim\n",
        "ChatGPT\n",
        "Untuk mendapatkan jumlah dimensi dari tensor dalam PyTorch, Anda dapat menggunakan metode dim() atau properti ndim. Namun, perlu diingat bahwa matriks adalah tensor dua dimensi.\n",
        "\n",
        "Berikut adalah contoh penggunaan untuk mendapatkan jumlah dimensi dari tensor matriks:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import torch\n",
        "\n",
        "MATRIX = torch.tensor([[7, 8], [9, 10]])\n",
        "print(MATRIX.dim())  # Output: 2\n",
        "Hasil dari MATRIX.dim() adalah 2, yang menunjukkan bahwa matriks memiliki dua dimensi. Jika Anda ingin menggunakan ndim, Anda dapat menggantinya dengan MATRIX.ndim, dan itu juga akan menghasilkan 2.\n",
        "\n",
        "User\n",
        "MATRIX.shape\n",
        "ChatGPT\n",
        "Untuk mendapatkan bentuk (shape) dari tensor matriks dalam PyTorch, Anda dapat menggunakan atribut shape. Berikut adalah contoh penggunaan:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import torch\n",
        "\n",
        "MATRIX = torch.tensor([[7, 8], [9, 10]])\n",
        "print(MATRIX.shape)\n",
        "Output yang diharapkan dari kode ini adalah (2, 2). Ini menunjukkan bahwa matriks memiliki dua dimensi, dengan dua elemen dalam dimensi pertama (baris) dan dua elemen dalam dimensi kedua (kolom). Jadi, bentuknya adalah tupel (2, 2).\n",
        "\n",
        "User\n",
        "# Check number of dimensions for TENSOR\n",
        "TENSOR.ndim\n",
        "ChatGPT\n",
        "It appears that the variable TENSOR is not defined in the provided context, so attempting to access its number of dimensions using TENSOR.ndim may result in an error. In PyTorch, you can use the dim() method or the ndim property to check the number of dimensions of a tensor.\n",
        "\n",
        "Here's an example assuming TENSOR is a PyTorch tensor:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import torch\n",
        "\n",
        "# Assuming TENSOR is a defined tensor\n",
        "TENSOR = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "# Check number of dimensions\n",
        "print(TENSOR.dim())  # Output: 2\n",
        "# Alternatively,\n",
        "print(TENSOR.ndim)   # Output: 2\n",
        "Make sure to replace the placeholder TENSOR with the actual tensor you are working with. The provided code will work if TENSOR is a valid PyTorch tensor.\n",
        "\n",
        "User\n",
        "terjemahkan\n",
        "ChatGPT\n",
        "Nampaknya variabel TENSOR tidak didefinisikan dalam konteks yang diberikan, sehingga mencoba mengakses jumlah dimensinya menggunakan TENSOR.ndim mungkin menghasilkan kesalahan. Dalam PyTorch, Anda dapat menggunakan metode dim() atau properti ndim untuk memeriksa jumlah dimensi dari suatu tensor.\n",
        "\n",
        "Berikut adalah contoh jika TENSOR adalah tensor PyTorch yang terdefinisi:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import torch\n",
        "\n",
        "# Asumsikan TENSOR adalah tensor yang terdefinisi\n",
        "TENSOR = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "# Periksa jumlah dimensi\n",
        "print(TENSOR.dim())  # Output: 2\n",
        "# Atau,\n",
        "print(TENSOR.ndim)   # Output: 2\n",
        "Pastikan untuk menggantikan placeholder TENSOR dengan tensor yang sesungguhnya sedang Anda kerjakan. Kode yang diberikan akan berfungsi jika TENSOR adalah tensor PyTorch yang valid.\n",
        "\n",
        "User\n",
        "# Check shape of TENSOR\n",
        "TENSOR.shape\n",
        "ChatGPT\n",
        "Dalam PyTorch, untuk mendapatkan bentuk (shape) dari suatu tensor, Anda dapat menggunakan atribut shape. Berikut adalah contoh penggunaan:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import torch\n",
        "\n",
        "# Asumsikan TENSOR adalah tensor yang terdefinisi\n",
        "TENSOR = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "# Periksa bentuk (shape) dari tensor\n",
        "print(TENSOR.shape)\n",
        "Output yang diharapkan dari kode ini adalah bentuk tensor, contohnya (2, 3). Ini menunjukkan bahwa tensor tersebut memiliki dua dimensi, dengan dua elemen dalam dimensi pertama (baris) dan tiga elemen dalam dimensi kedua (kolom). Jadi, bentuknya adalah tupel (2, 3). Pastikan untuk menggantikan placeholder TENSOR dengan tensor yang sesungguhnya sedang Anda kerjakan.\n",
        "\n",
        "User\n",
        "Berikan penjelasan dari kode\n",
        "# Check shape of TENSOR\n",
        "TENSOR.shape\n",
        "ChatGPT\n",
        "Kode di atas bertujuan untuk menampilkan bentuk (shape) dari suatu tensor yang disimpan dalam variabel TENSOR menggunakan atribut shape. Berikut adalah penjelasan singkat:\n",
        "\n",
        "TENSOR: Ini adalah variabel yang mengacu pada suatu tensor PyTorch yang sudah didefinisikan sebelumnya.\n",
        "\n",
        ".shape: Atribut ini digunakan untuk mendapatkan bentuk (shape) dari tensor. Bentuk tensor mencakup informasi tentang jumlah dimensi dan ukuran masing-masing dimensi.\n",
        "\n",
        "TENSOR.shape: Eksekusi perintah ini akan mengembalikan bentuk tensor yang diakses melalui atribut shape. Outputnya berupa tupel yang menyatakan jumlah elemen dalam setiap dimensi.\n",
        "\n",
        "Contoh output bisa berupa (2, 3), yang berarti tensor tersebut memiliki dua dimensi dengan dua elemen dalam dimensi pertama dan tiga elemen dalam dimensi kedua. Pastikan bahwa variabel TENSOR telah didefinisikan sebagai tensor PyTorch sebelumnya untuk menjalankan kode ini.\n",
        "\n",
        "User\n",
        "berikan penjelasan dari kode\n",
        "MATRIX.shape\n",
        "ChatGPT\n",
        "Kode MATRIX.shape bertujuan untuk menampilkan bentuk (shape) dari suatu tensor matriks yang disimpan dalam variabel MATRIX. Berikut adalah penjelasan singkat:\n",
        "\n",
        "MATRIX: Ini adalah variabel yang mengacu pada suatu tensor matriks PyTorch yang sudah didefinisikan sebelumnya.\n",
        "\n",
        ".shape: Atribut ini digunakan untuk mendapatkan bentuk (shape) dari tensor. Bentuk tensor mencakup informasi tentang jumlah dimensi dan ukuran masing-masing dimensi.\n",
        "\n",
        "MATRIX.shape: Eksekusi perintah ini akan mengembalikan bentuk tensor yang diakses melalui atribut shape. Outputnya berupa tupel yang menyatakan jumlah elemen dalam setiap dimensi.\n",
        "\n",
        "Contoh output bisa berupa (2, 2), yang berarti matriks tersebut memiliki dua dimensi dengan dua elemen dalam setiap dimensinya. Pastikan bahwa variabel MATRIX telah didefinisikan sebagai tensor matriks PyTorch sebelumnya untuk menjalankan kode ini.\n",
        "\n",
        "User\n",
        "berikan penjelasan dari kode\n",
        "# Tensor\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]])\n",
        "TENSOR\n",
        "ChatGPT\n",
        "Kode di atas menciptakan sebuah tensor tiga dimensi menggunakan PyTorch dan kemudian menampilkan nilai tensor tersebut. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.tensor([[[1, 2, 3], [3, 6, 9], [2, 4, 5]]]): Membuat tensor tiga dimensi dengan nilai yang diberikan. Dalam hal ini, tensor tersebut memiliki tiga dimensi: satu dimensi untuk \"tumpukan\" lapisan, satu dimensi untuk baris, dan satu dimensi untuk kolom.\n",
        "\n",
        "TENSOR: Variabel yang menampung tensor tiga dimensi yang baru dibuat.\n",
        "\n",
        "TENSOR: Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor tersebut. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi nilai tensor tiga dimensi yang ditentukan.\n",
        "\n",
        "Contoh output bisa terlihat seperti:\n",
        "\n",
        "lua\n",
        "Copy code\n",
        "tensor([[[1, 2, 3],\n",
        "         [3, 6, 9],\n",
        "         [2, 4, 5]]])\n",
        "Ini menunjukkan bahwa tensor tersebut memiliki tiga dimensi, dengan ukuran masing-masing dimensinya adalah 1, 3, dan 3. Pastikan bahwa variabel TENSOR telah didefinisikan sebagai tensor PyTorch sebelumnya untuk menjalankan kode ini.\n",
        "\n",
        "User\n",
        "berikan penjelasan dari kode\n",
        "# Check number of dimensions for TENSOR\n",
        "TENSOR.ndim\n",
        "ChatGPT\n",
        "Kode TENSOR.ndim mencoba untuk mengecek jumlah dimensi dari tensor yang disimpan dalam variabel TENSOR menggunakan properti ndim. Namun, perlu dicatat bahwa properti ndim tidak langsung tersedia pada objek tensor di PyTorch.\n",
        "\n",
        "Dalam PyTorch, untuk mendapatkan jumlah dimensi dari suatu tensor, Anda dapat menggunakan metode dim() atau properti ndim. Berikut adalah contoh penggunaan metode dim():\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import torch\n",
        "\n",
        "# Asumsikan TENSOR adalah tensor yang terdefinisi\n",
        "TENSOR = torch.tensor([[[1, 2, 3], [3, 6, 9], [2, 4, 5]]])\n",
        "\n",
        "# Periksa jumlah dimensi\n",
        "print(TENSOR.dim())  # Output: 3\n",
        "Hasil dari TENSOR.dim() adalah 3, yang menunjukkan bahwa tensor tersebut memiliki tiga dimensi. Properti ndim tidak umum digunakan dalam konteks PyTorch, jadi sebaiknya menggunakan metode dim() untuk memeriksa jumlah dimensi dari suatu tensor.\n",
        "\n",
        "User\n",
        "# Create a random tensor of size (3, 4)\n",
        "random_tensor = torch.rand(size=(3, 4))\n",
        "random_tensor, random_tensor.dtype\n",
        "berikan penjelasan dari kode diatas\n",
        "ChatGPT\n",
        "Kode di atas menciptakan sebuah tensor acak dengan ukuran (3, 4) menggunakan PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.rand(size=(3, 4)): Membuat tensor acak dengan ukuran (3, 4). Fungsi torch.rand() menghasilkan tensor dengan nilai acak yang terdistribusi seragam antara 0 dan 1. Parameter size digunakan untuk menentukan ukuran tensor yang diinginkan.\n",
        "\n",
        "random_tensor: Variabel yang menampung tensor acak yang baru dibuat.\n",
        "\n",
        "random_tensor.dtype: Mengakses properti dtype dari tensor untuk mendapatkan tipe data (dtype) tensor tersebut. Properti ini memberikan informasi tentang tipe data elemen dalam tensor.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor acak dan tipe datanya. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi nilai-nilai acak dan tipe data tensor tersebut.\n",
        "\n",
        "Contoh output bisa terlihat seperti:\n",
        "\n",
        "lua\n",
        "Copy code\n",
        "tensor([[0.1234, 0.5678, 0.8901, 0.2345],\n",
        "        [0.6789, 0.0123, 0.4567, 0.8901],\n",
        "        [0.2345, 0.6789, 0.0123, 0.4567]]), torch.float32\n",
        "Ini menunjukkan tensor acak dengan ukuran (3, 4) dan tipe data elemen float32. Pastikan bahwa variabel random_tensor telah didefinisikan sebelumnya untuk menjalankan kode ini.\n",
        "\n",
        "User\n",
        "berikan penjelasan dari kode\n",
        "# Create a random tensor of size (224, 224, 3)\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim\n",
        "ChatGPT\n",
        "Kode di atas menciptakan sebuah tensor acak dengan ukuran (224, 224, 3) menggunakan PyTorch. Namun, perlu dicatat bahwa hal ini dapat menyebabkan masalah karena ukuran ini tidak sesuai dengan konvensi untuk representasi gambar dalam bentuk tensor.\n",
        "\n",
        "Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.rand(size=(224, 224, 3)): Membuat tensor acak dengan ukuran (224, 224, 3). Fungsi torch.rand() menghasilkan tensor dengan nilai acak yang terdistribusi seragam antara 0 dan 1. Parameter size digunakan untuk menentukan ukuran tensor yang diinginkan.\n",
        "\n",
        "random_image_size_tensor: Variabel yang menampung tensor acak yang baru dibuat.\n",
        "\n",
        "random_image_size_tensor.shape: Mengakses atribut shape dari tensor untuk mendapatkan bentuk (shape) tensor tersebut. Bentuk tensor memberikan informasi tentang jumlah dimensi dan ukuran masing-masing dimensi.\n",
        "\n",
        "random_image_size_tensor.ndim: Mengakses metode ndim dari tensor untuk mendapatkan jumlah dimensi tensor tersebut.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan bentuk dan jumlah dimensi tensor. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi bentuk dan jumlah dimensi tensor tersebut.\n",
        "\n",
        "Perlu dicatat bahwa ukuran (224, 224, 3) tidak sesuai dengan representasi gambar yang umum digunakan dalam machine learning, di mana gambar biasanya diwakili sebagai tensor dengan dimensi (batch_size, channels, height, width). Jika Anda ingin menciptakan tensor gambar dengan ukuran (224, 224, 3), sebaiknya gunakan dimensi yang benar, misalnya, (1, 3, 224, 224) jika ini adalah satu gambar.\n",
        "\n",
        "User\n",
        "berikan penjelasan dari kode\n",
        "# Create a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros, zeros.dtype\n",
        "ChatGPT\n",
        "Kode di atas menciptakan sebuah tensor dengan semua elemen bernilai nol, menggunakan PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.zeros(size=(3, 4)): Membuat tensor dengan semua elemen bernilai nol dan ukuran (shape) (3, 4). Fungsi torch.zeros() menghasilkan tensor dengan elemen-elemen nol. Parameter size digunakan untuk menentukan ukuran tensor yang diinginkan.\n",
        "\n",
        "zeros: Variabel yang menampung tensor nol yang baru dibuat.\n",
        "\n",
        "zeros.dtype: Mengakses properti dtype dari tensor untuk mendapatkan tipe data (dtype) tensor tersebut. Properti ini memberikan informasi tentang tipe data elemen dalam tensor.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor nol dan tipe datanya. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi tensor dengan elemen-elemen nol dan tipe data tensor tersebut.\n",
        "\n",
        "Contoh output bisa terlihat seperti:\n",
        "\n",
        "lua\n",
        "Copy code\n",
        "tensor([[0., 0., 0., 0.],\n",
        "        [0., 0., 0., 0.],\n",
        "        [0., 0., 0., 0.]]), torch.float32\n",
        "Ini menunjukkan tensor dengan ukuran (3, 4) yang terdiri dari elemen-elemen nol dan memiliki tipe data elemen float32. Pastikan bahwa variabel zeros telah didefinisikan sebelumnya untuk menjalankan kode ini.\n",
        "\n",
        "User\n",
        "berikan penjelasan dari kode\n",
        "# Create a tensor of all ones\n",
        "ones = torch.ones(size=(3, 4))\n",
        "ones, ones.dtype\n",
        "ChatGPT\n",
        "Kode di atas menciptakan sebuah tensor dengan semua elemen bernilai satu, menggunakan PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.ones(size=(3, 4)): Membuat tensor dengan semua elemen bernilai satu dan ukuran (shape) (3, 4). Fungsi torch.ones() menghasilkan tensor dengan elemen-elemen satu. Parameter size digunakan untuk menentukan ukuran tensor yang diinginkan.\n",
        "\n",
        "ones: Variabel yang menampung tensor satu yang baru dibuat.\n",
        "\n",
        "ones.dtype: Mengakses properti dtype dari tensor untuk mendapatkan tipe data (dtype) tensor tersebut. Properti ini memberikan informasi tentang tipe data elemen dalam tensor.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor satu dan tipe datanya. Jika Anda mengeksekusi kode ini, Anda akan melihat keluaran yang berisi tensor dengan elemen-elemen satu dan tipe data tensor tersebut.\n",
        "\n",
        "Contoh output bisa terlihat seperti:\n",
        "\n",
        "lua\n",
        "Copy code\n",
        "tensor([[1., 1., 1., 1.],\n",
        "        [1., 1., 1., 1.],\n",
        "        [1., 1., 1., 1.]]), torch.float32\n",
        "Ini menunjukkan tensor dengan ukuran (3, 4) yang terdiri dari elemen-elemen satu dan memiliki tipe data elemen float32. Pastikan bahwa variabel ones telah didefinisikan sebelumnya untuk menjalankan kode ini.\n",
        "\n",
        "User\n",
        "berikan penjelasan dari kode\n",
        "# Use torch.arange(), torch.range() is deprecated\n",
        "zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n",
        "\n",
        "# Create a range of values 0 to 10\n",
        "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
        "zero_to_ten\n",
        "ChatGPT\n",
        "Kode di atas menciptakan tensor yang berisi rentang nilai dari 0 hingga 9 menggunakan dua metode berbeda: torch.range() yang sudah tidak direkomendasikan (deprecated) dan torch.arange(). Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.range(0, 10): Metode ini sebelumnya digunakan untuk membuat tensor yang berisi rentang nilai dari 0 hingga 10, namun metode ini sudah tidak direkomendasikan (deprecated). Catatan: ini mungkin menghasilkan kesalahan di masa depan karena telah di-deprecate.\n",
        "\n",
        "torch.arange(start=0, end=10, step=1): Metode ini lebih disarankan untuk membuat tensor yang berisi rentang nilai. torch.arange() memungkinkan Anda menentukan nilai awal (start), nilai akhir (end), dan langkah (step) untuk membuat rentang nilai.\n",
        "\n",
        "zero_to_ten: Variabel yang menampung tensor yang baru dibuat menggunakan torch.arange().\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor yang berisi rentang nilai dari 0 hingga 9.\n",
        "\n",
        "Contoh output yang diharapkan dari zero_to_ten adalah:\n",
        "\n",
        "scss\n",
        "Copy code\n",
        "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "Dalam hal ini, zero_to_ten akan berisi tensor dengan nilai-nilai yang membentuk rentang dari 0 hingga 9 (tidak termasuk 10) dengan langkah 1. Pastikan bahwa Anda menggunakan torch.arange() sebagai pengganti torch.range() yang sudah di-deprecate.\n",
        "\n",
        "User\n",
        "berikan penjelasan dari kode\n",
        "# Can also create a tensor of zeros similar to another tensor\n",
        "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
        "ten_zeros\n",
        "ChatGPT\n",
        "Kode di atas menciptakan sebuah tensor yang berisi nol dan memiliki bentuk (shape) yang sama dengan tensor lain (zero_to_ten). Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.zeros_like(input=zero_to_ten): Metode ini membuat tensor dengan elemen-elemen nol dan bentuk yang sama dengan tensor yang diberikan sebagai argumen (dalam hal ini, zero_to_ten). Fungsi ini memungkinkan pembuatan tensor dengan nol yang memiliki bentuk yang sesuai dengan tensor referensi.\n",
        "\n",
        "ten_zeros: Variabel yang menampung tensor nol yang baru dibuat, dengan bentuk yang sama seperti tensor zero_to_ten.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan nilai tensor yang berisi elemen-elemen nol dan memiliki bentuk yang sama dengan tensor referensi (zero_to_ten).\n",
        "\n",
        "Contoh output yang diharapkan dari ten_zeros akan memiliki bentuk yang sama seperti zero_to_ten dan elemen-elemen berisi nol, misalnya:\n",
        "\n",
        "scss\n",
        "Copy code\n",
        "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "Ini menunjukkan tensor dengan bentuk yang sesuai dengan zero_to_ten dan elemen-elemen yang semuanya nol. Pastikan bahwa variabel zero_to_ten telah didefinisikan sebelumnya untuk menjalankan kode ini.\n",
        "\n",
        "User\n",
        "berikan penjelasan dari kode\n",
        "# Default datatype for tensors is float32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
        "                               device=None, # defaults to None, which uses the default tensor type\n",
        "                               requires_grad=False) # if True, operations performed on the tensor are recorded\n",
        "\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device\n",
        "ChatGPT\n",
        "Kode di atas menciptakan tensor PyTorch yang berisi nilai float dengan tipe data float32 dan konfigurasi tambahan seperti bentuk (shape), perangkat (device), dan apakah gradient perlu dihitung atau tidak. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.tensor([3.0, 6.0, 9.0], dtype=None, device=None, requires_grad=False): Membuat tensor dengan elemen-elemen [3.0, 6.0, 9.0]. Argumen dtype digunakan untuk menentukan tipe data tensor, dan dalam kasus ini, diatur menjadi None, yang akan mengikuti default (torch.float32 atau tipe data apapun yang diberikan). Argumen device juga diatur menjadi None, yang berarti tensor akan dibuat di perangkat yang sesuai dengan konfigurasi default. Argumen requires_grad diatur menjadi False, yang berarti tensor tidak akan mencatat gradient saat operasi dijalankan pada tensor ini.\n",
        "\n",
        "float_32_tensor: Variabel yang menampung tensor yang baru dibuat.\n",
        "\n",
        "float_32_tensor.shape: Mengakses atribut shape dari tensor untuk mendapatkan bentuk (shape) tensor tersebut.\n",
        "\n",
        "float_32_tensor.dtype: Mengakses properti dtype dari tensor untuk mendapatkan tipe data (dtype) tensor tersebut.\n",
        "\n",
        "float_32_tensor.device: Mengakses properti device dari tensor untuk mendapatkan informasi perangkat di mana tensor ini ditempatkan.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan bentuk, tipe data, dan perangkat tensor.\n",
        "\n",
        "Contoh output yang diharapkan bisa terlihat seperti:\n",
        "(torch.Size([3]), torch.float32, 'cpu')\n",
        "Ini menunjukkan bahwa tensor memiliki bentuk dengan satu dimensi dan panjang 3, memiliki tipe data float32, dan ditempatkan di perangkat CPU ('cpu'). Pastikan bahwa variabel float_32_tensor telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "sRWRbPu89RdG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhP8kzDfe_ty"
      },
      "source": [
        "Aside from shape issues (tensor shapes don't match up), two of the other most common issues you'll come across in PyTorch are datatype and device issues.\n",
        "\n",
        "For example, one of tensors is `torch.float32` and the other is `torch.float16` (PyTorch often likes tensors to be the same format).\n",
        "\n",
        "Or one of your tensors is on the CPU and the other is on the GPU (PyTorch likes calculations between tensors to be on the same device).\n",
        "\n",
        "We'll see more of this device talk later on.\n",
        "\n",
        "For now let's create a tensor with `dtype=torch.float16`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKSuajld_09s",
        "outputId": "6343bcdc-7017-4f55-f491-1c3be0d5298c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float16) # torch.half would also work\n",
        "\n",
        "float_16_tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan tensor PyTorch yang berisi nilai float dengan tipe data float16 (torch.float16 atau torch.half). Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.tensor([3.0, 6.0, 9.0], dtype=torch.float16): Membuat tensor dengan elemen-elemen [3.0, 6.0, 9.0] dan menetapkan tipe data tensor sebagai float16. Argumen dtype digunakan untuk secara eksplisit menentukan tipe data tensor, dan dalam hal ini diatur sebagai torch.float16.\n",
        "\n",
        "float_16_tensor: Variabel yang menampung tensor yang baru dibuat.\n",
        "\n",
        "float_16_tensor.dtype: Mengakses properti dtype dari tensor untuk mendapatkan tipe data (dtype) tensor tersebut.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mencetak atau menampilkan tipe data tensor.\n",
        "\n",
        "Contoh output yang diharapkan adalah:\n",
        "torch.float16\n",
        "Ini menunjukkan bahwa tensor memiliki tipe data float16. Penggunaan tipe data float16 dapat mengurangi penggunaan memori tetapi dengan presisi yang lebih rendah dibandingkan dengan float32. Pastikan bahwa variabel float_16_tensor telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "57bu2Wmp9b0i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUjkB2AX7Upz"
      },
      "source": [
        "## Getting information from tensors\n",
        "\n",
        "Once you've created tensors (or someone else or a PyTorch module has created them for you), you might want to get some information from them.\n",
        "\n",
        "We've seen these before but three of the most common attributes you'll want to find out about tensors are:\n",
        "* `shape` - what shape is the tensor? (some operations require specific shape rules)\n",
        "* `dtype` - what datatype are the elements within the tensor stored in?\n",
        "* `device` - what device is the tensor stored on? (usually GPU or CPU)\n",
        "\n",
        "Let's create a random tensor and find out details about it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd_X4D0j7Umq",
        "outputId": "66bc82c4-15f7-4e03-c39d-11e80d0cf1d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4578, 0.4633, 0.2290, 0.6807],\n",
            "        [0.5562, 0.4106, 0.0170, 0.6215],\n",
            "        [0.7874, 0.7462, 0.0439, 0.8934]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor\n",
        "some_tensor = torch.rand(3, 4)\n",
        "\n",
        "# Find out details about it\n",
        "print(some_tensor)\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan tensor PyTorch dengan elemen-elemen yang dipilih secara acak dan kemudian mencetak atau menampilkan informasi tentang tensor tersebut. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.rand(3, 4): Membuat tensor dengan ukuran (shape) 3x4 yang berisi nilai acak yang terdistribusi seragam antara 0 dan 1. Fungsi torch.rand() digunakan untuk menciptakan tensor dengan nilai acak.\n",
        "\n",
        "some_tensor: Variabel yang menampung tensor yang baru dibuat.\n",
        "\n",
        "print(some_tensor): Mencetak atau menampilkan nilai tensor itu sendiri.\n",
        "\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\"): Mencetak atau menampilkan bentuk (shape) dari tensor. Bentuk tensor memberikan informasi tentang jumlah dimensi dan ukuran masing-masing dimensi.\n",
        "\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\"): Mencetak atau menampilkan tipe data (dtype) dari tensor. Tipe data tensor menentukan jenis nilai yang dapat dimiliki oleh tensor tersebut.\n",
        "\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\"): Mencetak atau menampilkan perangkat (device) tempat tensor disimpan. Dalam contoh ini, perangkat akan secara default diatur ke CPU ('cpu').\n",
        "\n",
        "Contoh output bisa terlihat seperti:\n",
        "\n",
        "tensor([[0.1234, 0.5678, 0.8901, 0.2345],\n",
        "        [0.6789, 0.0123, 0.4567, 0.8901],\n",
        "        [0.2345, 0.6789, 0.0123, 0.4567]])\n",
        "Shape of tensor: torch.Size([3, 4])\n",
        "Datatype of tensor: torch.float32\n",
        "Device tensor is stored on: cpu\n",
        "Ini menunjukkan tensor dengan nilai acak, bentuk (3, 4), tipe data float32, dan disimpan di perangkat CPU. Pastikan bahwa variabel some_tensor telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "jxM76OHk9ny4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45K-E5uPg6cj"
      },
      "source": [
        "> **Note:** When you run into issues in PyTorch, it's very often one to do with one of the three attributes above. So when the error messages show up, sing yourself a little song called \"what, what, where\":\n",
        "  * \"*what shape are my tensors? what datatype are they and where are they stored? what shape, what datatype, where where where*\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdiWvoAi7UjL"
      },
      "source": [
        "## Manipulating tensors (tensor operations)\n",
        "\n",
        "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
        "\n",
        "A model learns by investigating those tensors and performing a series of operations (could be 1,000,000s+) on tensors to create a representation of the patterns in the input data.\n",
        "\n",
        "These operations are often a wonderful dance between:\n",
        "* Addition\n",
        "* Substraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix multiplication\n",
        "\n",
        "And that's it. Sure there are a few more here and there but these are the basic building blocks of neural networks.\n",
        "\n",
        "Stacking these building blocks in the right way, you can create the most sophisticated of neural networks (just like lego!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk_6Dd7L7Uce"
      },
      "source": [
        "### Basic operations\n",
        "\n",
        "Let's start with a few of the fundamental operations, addition (`+`), subtraction (`-`), mutliplication (`*`).\n",
        "\n",
        "They work just as you think they would."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X71WpQoPD7a4",
        "outputId": "3d3723c0-b783-42e6-c334-da15e3e49043"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Create a tensor of values and add a number to it\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan tensor PyTorch dengan nilai [1, 2, 3] dan kemudian menambahkan nilai 10 ke setiap elemen tensor. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.tensor([1, 2, 3]): Membuat tensor dengan elemen-elemen [1, 2, 3]. Fungsi torch.tensor() digunakan untuk membuat tensor dari suatu list atau array.\n",
        "\n",
        "tensor + 10: Melakukan operasi penambahan pada setiap elemen tensor dengan nilai 10. PyTorch mendukung operasi matematika pada tensor, dan dalam hal ini, nilai 10 ditambahkan ke setiap elemen tensor.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mengeksekusi operasi penambahan dan hasilnya ditampilkan.\n",
        "\n",
        "Contoh output bisa terlihat seperti:\n",
        "tensor([11, 12, 13])\n",
        "Ini menunjukkan bahwa setiap elemen dalam tensor [1, 2, 3] telah ditambahkan dengan 10, menghasilkan tensor baru dengan nilai [11, 12, 13]. Pastikan bahwa variabel tensor telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "NrnXUXxr90XV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp4TlTWWEFeO",
        "outputId": "0c9fd83f-89ce-45e2-be69-9704b267c097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Multiply it by 10\n",
        "tensor * 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas mengambil tensor PyTorch yang sudah ada dengan nilai [1, 2, 3] dan mengalikan setiap elemennya dengan nilai 10. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor * 10: Melakukan operasi perkalian pada setiap elemen tensor dengan nilai 10. PyTorch mendukung operasi matematika pada tensor, dan dalam hal ini, setiap elemen tensor dikalikan dengan 10.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mengeksekusi operasi perkalian dan menampilkan hasilnya.\n",
        "\n",
        "Contoh output bisa terlihat seperti:\n",
        "tensor([10, 20, 30])\n",
        "Ini menunjukkan bahwa setiap elemen dalam tensor [1, 2, 3] telah dikalikan dengan 10, menghasilkan tensor baru dengan nilai [10, 20, 30]. Pastikan bahwa variabel tensor telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "2TbkDfFZ99dV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1VEHnuRkn8Q"
      },
      "source": [
        "Notice how the tensor values above didn't end up being `tensor([110, 120, 130])`, this is because the values inside the tensor don't change unless they're reassigned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuB1UjCIEJIA",
        "outputId": "98126415-6364-4cbb-bfde-36367d2211dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Tensors don't change unless reassigned\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode tersebut mencoba menampilkan nilai dari tensor yang telah diubah sebelumnya dengan operasi perkalian (dikali 10). Penjelasan singkatnya adalah:\n",
        "\n",
        "tensor: Baris kode ini adalah untuk menampilkan nilai tensor tanpa melakukan reassign atau pengubahan nilai pada variabel. Hal ini mencoba menunjukkan bahwa operasi perkalian sebelumnya (tensor * 10) tidak secara permanen mengubah nilai tensor kecuali nilai tersebut diassign kembali ke variabel.\n",
        "Contoh outputnya mungkin akan menunjukkan nilai tensor setelah operasi perkalian sebelumnya:\n",
        "tensor([10, 20, 30])\n",
        "Namun, penting untuk dicatat bahwa ini hanya menampilkan nilai tensor untuk keperluan pengamatan atau inspeksi sementara, dan nilai tensor sebenarnya tidak diubah kecuali variabel tensor diassign kembali dengan hasil operasi tersebut."
      ],
      "metadata": {
        "id": "48SkCcaI-H6R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYvqGpUTk1o6"
      },
      "source": [
        "Let's subtract a number and this time we'll reassign the `tensor` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4iWKoLsENry",
        "outputId": "d11a1991-ba78-4a63-9cd5-068b8c2c3ed9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Subtract and reassign\n",
        "tensor = tensor - 10\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode tersebut mengambil tensor yang telah dimodifikasi sebelumnya (hasil perkalian dengan 10) dan kemudian mengurangkan nilai 10 dari setiap elemennya. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor = tensor - 10: Melakukan operasi pengurangan pada setiap elemen tensor dengan nilai 10, dan kemudian menugaskan hasilnya kembali ke variabel tensor. Dengan melakukan ini, nilai tensor diperbarui dengan hasil pengurangan.\n",
        "\n",
        "tensor: Baris ini adalah untuk menampilkan nilai tensor setelah operasi pengurangan dan reassign. Nilai tensor sekarang adalah nilai sebelumnya yang dikalikan dengan 10, kemudian dikurangkan dengan 10.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai tensor setelah operasi pengurangan dan reassign:\n",
        "tensor([0, 10, 20])\n",
        "Ini menunjukkan bahwa setiap elemen dalam tensor telah dikurangkan dengan 10, menghasilkan tensor baru dengan nilai [0, 10, 20]. Variabel tensor sekarang berisi nilai yang telah diperbarui."
      ],
      "metadata": {
        "id": "eogDyRkR-Q3H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFgZY-PaFNXa",
        "outputId": "56e9fd40-78e3-45fa-f47f-8eb1554a91b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Add and reassign\n",
        "tensor = tensor + 10\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode tersebut mengambil tensor yang telah dimodifikasi sebelumnya (hasil pengurangan dengan 10) dan kemudian menambahkan nilai 10 ke setiap elemennya. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor = tensor + 10: Melakukan operasi penambahan pada setiap elemen tensor dengan nilai 10, dan kemudian menugaskan hasilnya kembali ke variabel tensor. Dengan melakukan ini, nilai tensor diperbarui dengan hasil penambahan.\n",
        "\n",
        "tensor: Baris ini adalah untuk menampilkan nilai tensor setelah operasi penambahan dan reassign. Nilai tensor sekarang adalah nilai sebelumnya yang telah dikurangkan dengan 10, kemudian ditambahkan dengan 10.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai tensor setelah operasi penambahan dan reassign:\n",
        "tensor([10, 20, 30])\n",
        "Ini menunjukkan bahwa setiap elemen dalam tensor telah ditambahkan dengan 10, menghasilkan tensor baru dengan nilai [10, 20, 30]. Variabel tensor sekarang berisi nilai yang telah diperbarui."
      ],
      "metadata": {
        "id": "pDVEZYlS-Zeq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYXDoIOzk-6I"
      },
      "source": [
        "PyTorch also has a bunch of built-in functions like [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) (short for multiplication) and [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html) to perform basic operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVysdk3kFWbY",
        "outputId": "3ad8cba9-0bc4-42c1-9098-2199df9a0681"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Can also use torch functions\n",
        "torch.multiply(tensor, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode tersebut mencoba mengalikan setiap elemen dari tensor tensor dengan nilai 10 menggunakan fungsi torch.multiply(). Namun, perlu dicatat bahwa fungsi tersebut sebenarnya tidak ada di PyTorch. Operasi perkalian pada tensor dalam PyTorch dapat dilakukan menggunakan operator * atau menggunakan fungsi-fungsi seperti torch.mul().\n",
        "\n",
        "Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.multiply(tensor, 10): Baris ini mencoba menggunakan fungsi torch.multiply() untuk mengalikan setiap elemen dari tensor tensor dengan nilai 10. Namun, fungsi torch.multiply() sebenarnya tidak ada di PyTorch.\n",
        "Untuk melakukan operasi perkalian pada tensor dalam PyTorch, Anda dapat menggunakan operator * atau menggunakan fungsi torch.mul(). Berikut adalah contoh penggunaan:\n",
        "\n",
        "Menggunakan operator *:\n",
        "multiplied_tensor = tensor * 10\n",
        "Menggunakan fungsi torch.mul():\n",
        "multiplied_tensor = torch.mul(tensor, 10)\n",
        "Kode yang benar untuk mengalikan setiap elemen tensor dengan 10 menggunakan fungsi PyTorch adalah menggunakan operator * atau fungsi torch.mul()."
      ],
      "metadata": {
        "id": "FKLAU4-n-i3J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxuPJIpNFbqO",
        "outputId": "7242752d-6c08-4dc8-a619-279ae24ac2dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Original tensor is still unchanged\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode tersebut mencoba menunjukkan bahwa tensor asli (sebelum operasi perkalian atau pengurangan) tetap tidak berubah meskipun telah dilakukan operasi matematika pada tensor tersebut. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor: Baris ini adalah untuk menampilkan nilai tensor. Karena tidak ada operasi perubahan yang dilakukan pada tensor setelah operasi perkalian dan pengurangan, nilai tensor yang ditampilkan adalah nilai asli tensor sebelum operasi tersebut.\n",
        "Contoh outputnya mungkin akan menunjukkan nilai tensor sebelum dilakukan operasi perubahan:\n",
        "tensor([1, 2, 3])\n",
        "Ini menunjukkan bahwa meskipun telah dilakukan operasi perkalian dan pengurangan pada tensor menggunakan variabel baru (yang telah di-assign hasilnya), nilai asli dari tensor tetap tidak berubah. Variabel tensor masih berisi nilai [1, 2, 3], yang merupakan nilai tensor sebelum operasi perubahan."
      ],
      "metadata": {
        "id": "tNI3_nrVFAMF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70UNL33AlVQq"
      },
      "source": [
        "However, it's more common to use the operator symbols like `*` instead of `torch.mul()`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode tersebut mencoba menunjukkan bahwa tensor asli (sebelum operasi perkalian atau pengurangan) tetap tidak berubah meskipun telah dilakukan operasi matematika pada tensor tersebut. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor: Baris ini adalah untuk menampilkan nilai tensor. Karena tidak ada operasi perubahan yang dilakukan pada tensor setelah operasi perkalian dan pengurangan, nilai tensor yang ditampilkan adalah nilai asli tensor sebelum operasi tersebut.\n",
        "Contoh outputnya mungkin akan menunjukkan nilai tensor sebelum dilakukan operasi perubahan:\n",
        "\n",
        "scss\n",
        "Copy code\n",
        "tensor([1, 2, 3])\n",
        "Ini menunjukkan bahwa meskipun telah dilakukan operasi perkalian dan pengurangan pada tensor menggunakan variabel baru (yang telah di-assign hasilnya), nilai asli dari tensor tetap tidak berubah. Variabel tensor masih berisi nilai [1, 2, 3], yang merupakan nilai tensor sebelum operasi perubahan."
      ],
      "metadata": {
        "id": "LzUNe2oo_qQp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5v3RkR0F2Jq",
        "outputId": "d965f9e6-2521-4c34-e2d7-7ec22f4f916c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n"
          ]
        }
      ],
      "source": [
        "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
        "print(tensor, \"*\", tensor)\n",
        "print(\"Equals:\", tensor * tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode tersebut mencoba menunjukkan operasi perkalian pada setiap elemen tensor dengan dirinya sendiri (operasi perkalian bersifat element-wise). Berikut adalah penjelasan singkat:\n",
        "\n",
        "print(tensor, \"*\", tensor): Baris ini mencetak atau menampilkan tensor, tanda perkalian *, dan tensor lagi. Tujuannya adalah untuk menunjukkan operasi element-wise multiplication pada setiap elemen tensor dengan dirinya sendiri. Misalnya, untuk tensor [1, 2, 3], hasilnya akan ditampilkan sebagai tensor * tensor.\n",
        "\n",
        "print(\"Equals:\", tensor * tensor): Baris ini mencetak atau menampilkan hasil dari operasi perkalian element-wise tersebut. Hasilnya adalah tensor baru yang elemennya merupakan hasil perkalian element-wise dari tensor awal dengan dirinya sendiri.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai tensor dan hasil perkalian element-wise:\n",
        "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
        "Equals: tensor([1, 4, 9])\n",
        "Ini menunjukkan bahwa setiap elemen pada tensor [1, 2, 3] dikalikan dengan elemen yang sesuai dari tensor [1, 2, 3], menghasilkan tensor baru [1, 4, 9]. Hasil ini diperoleh dengan mengalikan elemen-elemen pada posisi yang sesuai satu sama lain."
      ],
      "metadata": {
        "id": "9YOqAWaCFHIr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT5fVuyu7q5z"
      },
      "source": [
        "### Matrix multiplication (is all you need)\n",
        "\n",
        "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is [matrix multiplication](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
        "\n",
        "PyTorch implements matrix multiplication functionality in the [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) method.\n",
        "\n",
        "The main two rules for matrix multiplication to remember are:\n",
        "\n",
        "1. The **inner dimensions** must match:\n",
        "  * `(3, 2) @ (3, 2)` won't work\n",
        "  * `(2, 3) @ (3, 2)` will work\n",
        "  * `(3, 2) @ (2, 3)` will work\n",
        "2. The resulting matrix has the shape of the **outer dimensions**:\n",
        " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
        " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
        "\n",
        "> **Note:** \"`@`\" in Python is the symbol for matrix multiplication.\n",
        "\n",
        "> **Resource:** You can see all of the rules for matrix multiplication using `torch.matmul()` [in the PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
        "\n",
        "Let's create a tensor and perform element-wise multiplication and matrix multiplication on it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE7loucmDlEM",
        "outputId": "401a5f32-63a3-491e-9d43-ce07bf643022"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import torch\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan PyTorch untuk membuat sebuah tensor dengan nilai [1, 2, 3] dan kemudian mengakses atribut shape dari tensor tersebut. Berikut adalah penjelasan singkat:\n",
        "\n",
        "import torch: Mengimpor pustaka PyTorch ke dalam program Python.\n",
        "\n",
        "tensor = torch.tensor([1, 2, 3]): Membuat tensor dengan elemen-elemen [1, 2, 3] menggunakan fungsi torch.tensor().\n",
        "\n",
        "tensor.shape: Mengakses atribut shape dari tensor. Atribut shape memberikan informasi tentang jumlah dimensi dan ukuran masing-masing dimensi dalam tensor.\n",
        "\n",
        "Baris terakhir dari kode tersebut adalah untuk mengeksekusi akses ke atribut shape dan menampilkan hasilnya.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan bentuk (shape) dari tensor:\n",
        "torch.Size([3])\n",
        "Ini menunjukkan bahwa tensor memiliki satu dimensi (vektor) dengan panjang 3. Atribut shape menunjukkan jumlah elemen dalam setiap dimensi. Dalam hal ini, satu dimensi dengan panjang 3. Pastikan bahwa variabel tensor telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "G-m8eA2kFV0T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUAZ3_b0vOKv"
      },
      "source": [
        "The difference between element-wise multiplication and matrix multiplication is the addition of values.\n",
        "\n",
        "For our `tensor` variable with values `[1, 2, 3]`:\n",
        "\n",
        "| Operation | Calculation | Code |\n",
        "| ----- | ----- | ----- |\n",
        "| **Element-wise multiplication** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
        "| **Matrix multiplication** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i42gkUeHvI_1",
        "outputId": "22a6e586-0680-4f9c-fb1a-e3d7b9353c92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Element-wise matrix multiplication\n",
        "tensor * tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas mencoba melakukan operasi perkalian matriks secara elemen-wise pada tensor. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor * tensor: Baris ini mencoba melakukan operasi perkalian matriks secara elemen-wise pada tensor. Operasi ini mengalikan setiap elemen pada tensor dengan elemen yang sesuai dari tensor itu sendiri.\n",
        "Contoh outputnya mungkin akan menunjukkan hasil operasi perkalian elemen-wise:\n",
        "tensor([1, 4, 9])\n",
        "Ini menunjukkan bahwa setiap elemen pada tensor [1, 2, 3] dikalikan dengan elemen yang sesuai dari tensor [1, 2, 3], menghasilkan tensor baru [1, 4, 9]. Hasil ini adalah hasil dari operasi perkalian elemen-wise pada vektor (tensor 1D). Operasi perkalian elemen-wise ini dilakukan pada elemen dengan indeks yang sesuai satu sama lain."
      ],
      "metadata": {
        "id": "_CDNvyFqFiEA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvCBiiTTDk8y",
        "outputId": "1609cf02-f140-48cc-ce12-b5a20a061d1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Matrix multiplication\n",
        "torch.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Kode di atas mencoba melakukan operasi perkalian matriks pada tensor menggunakan fungsi torch.matmul(). Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.matmul(tensor, tensor): Baris ini menggunakan fungsi torch.matmul() untuk melakukan operasi perkalian matriks pada tensor. Operasi ini menghasilkan hasil perkalian matriks standar, dan aturan dimensi untuk perkalian matriks harus dipenuhi (jumlah kolom matriks pertama harus sama dengan jumlah baris matriks kedua).\n",
        "Contoh outputnya mungkin akan menunjukkan hasil perkalian matriks:\n",
        "tensor(14)\n",
        "Ini menunjukkan bahwa hasil perkalian matriks dari tensor [1, 2, 3] dengan tensor [1, 2, 3] adalah skalar 14. Hasil ini adalah hasil dari perkalian matriks standar yang mengikuti aturan perkalian matriks. Pastikan bahwa variabel tensor telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "nqNuX_SEFt59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4E_pROBDk2r",
        "outputId": "9d49dae0-5458-4e60-beac-5b53d6e6886c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Can also use the \"@\" symbol for matrix multiplication, though not recommended\n",
        "tensor @ tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas mencoba melakukan operasi perkalian matriks pada tensor menggunakan operator @. Meskipun operator ini bisa digunakan untuk operasi perkalian matriks, disarankan untuk menggunakan fungsi torch.matmul() untuk kejelasan dan konsistensi. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor @ tensor: Baris ini menggunakan operator @ untuk melakukan operasi perkalian matriks pada tensor. Operator @ dapat digunakan untuk melakukan perkalian matriks, tetapi tidak disarankan untuk kejelasan kode.\n",
        "Contoh outputnya mungkin akan menunjukkan hasil perkalian matriks:\n",
        "tensor(14)\n",
        "Ini menunjukkan bahwa hasil perkalian matriks dari tensor [1, 2, 3] dengan tensor [1, 2, 3] adalah skalar 14. Hasil ini sama dengan hasil yang diperoleh menggunakan torch.matmul(). Meskipun operator @ dapat digunakan, lebih disarankan untuk menggunakan fungsi torch.matmul() agar kode lebih mudah dibaca dan konsisten. Pastikan bahwa variabel tensor telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "F2120fP8F5YL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obbginUMv43A"
      },
      "source": [
        "You can do matrix multiplication by hand but it's not recommended.\n",
        "\n",
        "The in-built `torch.matmul()` method is faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qMSaLOoJscL",
        "outputId": "5dcce166-67ea-46d0-fbb2-251f491df120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.44 ms, sys: 0 ns, total: 1.44 ms\n",
            "Wall time: 1.39 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "%%time\n",
        "# Matrix multiplication by hand\n",
        "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "value"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode tersebut mencoba melakukan perkalian matriks secara manual, menghindari penggunaan operasi matriks bawaan PyTorch, dan mengukur waktu yang dibutuhkan untuk operasi tersebut menggunakan cell magic %%time. Berikut adalah penjelasan singkat:\n",
        "\n",
        "%%time: Cell magic command ini digunakan untuk mengukur waktu eksekusi seluruh sel kode di sel yang sama. Dengan menggunakan %%time, kita dapat melihat berapa lama waktu yang dibutuhkan untuk mengeksekusi seluruh kode di sel tersebut.\n",
        "\n",
        "Baris berikutnya melakukan perkalian matriks secara manual dengan menggunakan loop for:\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "Kode ini mengiterasi melalui elemen-elemen tensor dan melakukan operasi perkalian matriks secara manual. Setiap elemen dari tensor dikalikan dengan dirinya sendiri, dan hasilnya diakumulasi dalam variabel value.\n",
        "\n",
        "value: Baris ini mengembalikan atau menampilkan hasil dari operasi perkalian matriks yang dilakukan secara manual.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan hasil dari operasi perkalian matriks secara manual dan waktu yang dibutuhkan untuk eksekusi:\n",
        "tensor(14)\n",
        "CPU times: user 136 µs, sys: 45 µs, total: 181 µs\n",
        "Wall time: 191 µs\n",
        "Hasil dari operasi perkalian matriks secara manual adalah skalar 14. Waktu eksekusi ditampilkan di bawahnya, memberikan informasi tentang waktu yang dibutuhkan untuk mengeksekusi seluruh sel tersebut. Perlu diingat bahwa cara ini untuk melakukan perkalian matriks tidak efisien dan kurang disarankan untuk ukuran matriks yang besar karena penggunaan loop for dapat menjadi komputasi yang mahal secara komputasional. Sebaiknya, gunakan fungsi-fungsi matriks bawaan PyTorch seperti torch.matmul() untuk operasi matriks yang lebih efisien."
      ],
      "metadata": {
        "id": "i4KNjJqrGDku"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVWiKB0KwH74",
        "outputId": "e2c3c5ea-a84b-4917-ed19-161815b9a13b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 75 µs, sys: 0 ns, total: 75 µs\n",
            "Wall time: 78.9 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode tersebut menggunakan cell magic %%time untuk mengukur waktu yang dibutuhkan untuk menjalankan operasi perkalian matriks menggunakan fungsi PyTorch torch.matmul(). Berikut adalah penjelasan singkat:\n",
        "\n",
        "%%time: Cell magic command ini digunakan untuk mengukur waktu eksekusi seluruh sel kode di sel yang sama. Dengan menggunakan %%time, kita dapat melihat berapa lama waktu yang dibutuhkan untuk mengeksekusi seluruh kode di sel tersebut.\n",
        "\n",
        "torch.matmul(tensor, tensor): Baris ini menggunakan fungsi torch.matmul() untuk melakukan operasi perkalian matriks pada tensor. Operasi ini dilakukan dengan efisien menggunakan implementasi PyTorch.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan hasil dari operasi perkalian matriks dan waktu yang dibutuhkan untuk eksekusinya:\n",
        "tensor(14)\n",
        "CPU times: user 1.35 ms, sys: 36 µs, total: 1.39 ms\n",
        "Wall time: 1.2 ms\n",
        "Hasil dari operasi perkalian matriks menggunakan PyTorch adalah skalar 14. Waktu eksekusi ditampilkan di bawahnya, memberikan informasi tentang waktu yang dibutuhkan untuk mengeksekusi seluruh sel tersebut. Perlu diingat bahwa menggunakan fungsi-fungsi matriks bawaan PyTorch seperti torch.matmul() lebih disarankan untuk operasi matriks, karena dapat memberikan kinerja yang lebih baik dan lebih efisien dibandingkan dengan implementasi manual menggunakan loop for."
      ],
      "metadata": {
        "id": "sC0YRG7AGP56"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ4DDmo1TGe-"
      },
      "source": [
        "## One of the most common errors in deep learning (shape errors)\n",
        "\n",
        "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN5RcoD4Jo6y",
        "outputId": "a40f97cb-9b64-44d5-a5dc-085282a185a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n"
          ]
        }
      ],
      "source": [
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "# Transpose tensor_B to make the matrix multiplication valid\n",
        "tensor_B_transposed = torch.transpose(tensor_B, 0, 1)\n",
        "\n",
        "result = torch.matmul(tensor_A, tensor_B_transposed)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "torch.matmul(tensor_A, tensor_B) # (this will error)\n",
        "kode diatas saat akan di run terjadi error, error ini muncul karena ketidakcocokan bentuk (shape) tensor yang dioperasikan oleh fungsi torch.matmul. Untuk mengatasi error ini, kita perlu mengubah bentuk salah satu tensor sehingga memenuhi persyaratan perkalian matriks. Dengan melakukan transposisi tensor_B menggunakan torch.transpose(tensor_B, 0, 1), kita mengubah bentuk tensor_B dari (3x2) menjadi (2x3), sehingga dapat dioperasikan dengan tensor_A yang memiliki bentuk (3x2)."
      ],
      "metadata": {
        "id": "2JSq3YieNzSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode tersebut melakukan perkalian matriks antara dua tensor PyTorch (tensor_A dan tensor_B) dan kemudian mencetak hasilnya. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor_A = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float32): Membuat tensor tensor_A dengan nilai [[1, 2], [3, 4], [5, 6]] dan tipe data float32.\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10], [8, 11], [9, 12]], dtype=torch.float32): Membuat tensor tensor_B dengan nilai [[7, 10], [8, 11], [9, 12]] dan tipe data float32.\n",
        "\n",
        "tensor_B_transposed = torch.transpose(tensor_B, 0, 1): Melakukan operasi transpose pada tensor_B. Ini diperlukan karena bentuk (shape) tensor_A adalah (3, 2), dan bentuk tensor_B adalah (3, 2). Agar dapat melakukan perkalian matriks, jumlah kolom matriks pertama harus sama dengan jumlah baris matriks kedua. Dengan mengubah bentuk tensor_B menjadi (2, 3), kita memastikan bahwa operasi perkalian matriks dapat dilakukan.\n",
        "\n",
        "result = torch.matmul(tensor_A, tensor_B_transposed): Melakukan operasi perkalian matriks antara tensor_A dan tensor_B_transposed. Hasilnya disimpan dalam variabel result.\n",
        "\n",
        "print(result): Mencetak hasil perkalian matriks.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan hasil perkalian matriks:\n",
        "tensor([[ 27.,  31.,  35.],\n",
        "        [ 61.,  71.,  81.],\n",
        "        [ 95., 111., 127.]])\n",
        "Ini menunjukkan hasil perkalian matriks dari tensor_A dan tensor_B_transposed. Setiap elemen dari hasil matriks adalah hasil perkalian dot produk dari baris tensor_A dengan kolom tensor_B_transposed. Pastikan bahwa variabel tensor_A dan tensor_B telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "m3elKWj4GcRa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNA6MZEFxWVt"
      },
      "source": [
        "We can make matrix multiplication work between `tensor_A` and `tensor_B` by making their inner dimensions match.\n",
        "\n",
        "One of the ways to do this is with a **transpose** (switch the dimensions of a given tensor).\n",
        "\n",
        "You can perform transposes in PyTorch using either:\n",
        "* `torch.transpose(input, dim0, dim1)` - where `input` is the desired tensor to transpose and `dim0` and `dim1` are the dimensions to be swapped.\n",
        "* `tensor.T` - where `tensor` is the desired tensor to transpose.\n",
        "\n",
        "Let's try the latter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUqgaANiy1wq",
        "outputId": "f4d9a490-d99b-4989-e135-f714e4bb9a92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7., 10.],\n",
            "        [ 8., 11.],\n",
            "        [ 9., 12.]])\n"
          ]
        }
      ],
      "source": [
        "# View tensor_A and tensor_B\n",
        "print(tensor_A)\n",
        "print(tensor_B)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas mencetak atau menampilkan nilai dari dua tensor PyTorch, yaitu tensor_A dan tensor_B. Berikut adalah penjelasan singkat:\n",
        "\n",
        "print(tensor_A): Baris ini mencetak atau menampilkan nilai dari tensor tensor_A. Variabel tensor_A adalah sebuah matriks dengan nilai [[1, 2], [3, 4], [5, 6]].\n",
        "\n",
        "print(tensor_B): Baris ini mencetak atau menampilkan nilai dari tensor tensor_B. Variabel tensor_B adalah sebuah matriks dengan nilai [[7, 10], [8, 11], [9, 12]].\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari kedua tensor:\n",
        "tensor([[1., 2.],\n",
        "        [3., 4.],\n",
        "        [5., 6.]])\n",
        "tensor([[ 7., 10.],\n",
        "        [ 8., 11.],\n",
        "        [ 9., 12.]])\n",
        "Ini menampilkan nilai dari tensor_A dan tensor_B secara berurutan. Setiap tensor memiliki bentuk (shape) dan nilai matriks yang sesuai. Pastikan bahwa variabel tensor_A dan tensor_B telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "VTjIXYt_GlQX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DveqxO7iy_Fi",
        "outputId": "8ecff2fd-1fc3-45d1-eb54-acdbcff1cbc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n"
          ]
        }
      ],
      "source": [
        "# View tensor_A and tensor_B.T\n",
        "print(tensor_A)\n",
        "print(tensor_B.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas mencetak atau menampilkan nilai dari dua tensor PyTorch, yaitu tensor_A dan transpose dari tensor_B (tensor_B.T). Berikut adalah penjelasan singkat:\n",
        "\n",
        "print(tensor_A): Baris ini mencetak atau menampilkan nilai dari tensor tensor_A. Variabel tensor_A adalah sebuah matriks dengan nilai [[1, 2], [3, 4], [5, 6]].\n",
        "\n",
        "print(tensor_B.T): Baris ini mencetak atau menampilkan nilai dari transpose tensor tensor_B. Operasi transpose dilakukan dengan menukar baris menjadi kolom dan sebaliknya. Dengan kata lain, setiap elemen di posisi (i, j) dalam tensor menjadi elemen di posisi (j, i) dalam tensor transpose. Variabel tensor_B.T adalah matriks transpose dari tensor_B.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari tensor_A dan transpose dari tensor_B:\n",
        "tensor([[1., 2.],\n",
        "        [3., 4.],\n",
        "        [5., 6.]])\n",
        "tensor([[ 7.,  8.,  9.],\n",
        "        [10., 11., 12.]])\n",
        "Ini menampilkan nilai dari tensor_A dan matriks transpose dari tensor_B. Perhatikan bahwa elemen-elemen di tensor transpose telah ditukar antara baris dan kolom. Pastikan bahwa variabel tensor_A dan tensor_B telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "eX9_F6fNHHdU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35rEIu-NKtVE",
        "outputId": "c848a4ee-8bf5-4e1d-f577-93a8ac87223c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# The operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas mencoba menjelaskan mengapa operasi perkalian matriks (torch.matmul()) bekerja ketika tensor_B di-transpose (tensor_B.T). Berikut adalah penjelasan singkat:\n",
        "\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\"): Baris ini mencetak atau menampilkan bentuk (shape) asli dari tensor_A dan tensor_B.\n",
        "\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\"): Baris ini mencetak atau menampilkan bentuk (shape) dari tensor_A (tidak berubah) dan bentuk dari transpose tensor_B (tensor_B.T).\n",
        "\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\"): Baris ini mencetak atau menampilkan pesan yang menjelaskan bahwa operasi perkalian matriks dapat dilakukan karena dimensi dalam (\"inner dimensions\") tensor sesuai. Dalam konteks ini, bentuk (shape) tensor_A adalah (3, 2), dan bentuk transpose dari tensor_B (tensor_B.T) adalah (2, 3). Inner dimensions yang sesuai adalah 2 dan 2.\n",
        "\n",
        "output = torch.matmul(tensor_A, tensor_B.T): Baris ini melakukan operasi perkalian matriks antara tensor_A dan transpose tensor_B (tensor_B.T). Hasilnya disimpan dalam variabel output.\n",
        "\n",
        "print(output): Baris ini mencetak atau menampilkan hasil dari operasi perkalian matriks.\n",
        "\n",
        "print(f\"\\nOutput shape: {output.shape}\"): Baris ini mencetak atau menampilkan bentuk (shape) dari hasil (output) operasi perkalian matriks.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan bentuk (shape) dan hasil dari operasi perkalian matriks:\n",
        "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
        "\n",
        "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
        "\n",
        "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
        "\n",
        "Output:\n",
        "\n",
        "tensor([[ 27.,  31.,  35.],\n",
        "        [ 61.,  71.,  81.],\n",
        "        [ 95., 111., 127.]])\n",
        "\n",
        "Output shape: torch.Size([3, 3])\n",
        "Ini memberikan pemahaman tentang bagaimana bentuk tensor memengaruhi operasi perkalian matriks dan mengapa transposisi tensor B diperlukan untuk membuat operasi ini valid. Pastikan bahwa variabel tensor_A dan tensor_B telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "8LiS1GJbHVlh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfcFEqfLjN24"
      },
      "source": [
        "You can also use [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html) which is a short for `torch.matmul()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3rJvW_TTGe_",
        "outputId": "4e1b16f3-4b30-4824-cb52-60b13659daf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# torch.mm is a shortcut for matmul\n",
        "torch.mm(tensor_A, tensor_B.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan fungsi torch.mm() untuk melakukan operasi perkalian matriks antara tensor_A dan transpose dari tensor_B (tensor_B.T). Fungsi torch.mm() merupakan pintasan (shortcut) untuk operasi perkalian matriks pada PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.mm(tensor_A, tensor_B.T): Baris ini menggunakan fungsi torch.mm() untuk melakukan operasi perkalian matriks antara tensor_A (matriks 3x2) dan transpose dari tensor_B (tensor_B.T, matriks 2x3). Hasilnya adalah matriks berukuran 3x3.\n",
        "Contoh outputnya mungkin akan menunjukkan hasil dari operasi perkalian matriks:\n",
        "tensor([[ 27.,  31.,  35.],\n",
        "        [ 61.,  71.,  81.],\n",
        "        [ 95., 111., 127.]])\n",
        "Ini memberikan hasil yang sama seperti menggunakan torch.matmul(), tetapi dengan menggunakan fungsi singkat torch.mm(). Fungsi ini dapat digunakan untuk melakukan operasi perkalian matriks pada dua tensor berukuran 2D. Pastikan bahwa variabel tensor_A dan tensor_B telah didefinisikan sebelumnya untuk menjalankan kode ini."
      ],
      "metadata": {
        "id": "XKLRkE7EHi35"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXKozI4T0hFi"
      },
      "source": [
        "Without the transpose, the rules of matrix mulitplication aren't fulfilled and we get an error like above.\n",
        "\n",
        "How about a visual?\n",
        "\n",
        "![visual demo of matrix multiplication](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/00-matrix-multiply-crop.gif)\n",
        "\n",
        "You can create your own matrix multiplication visuals like this at http://matrixmultiplication.xyz/.\n",
        "\n",
        "> **Note:** A matrix multiplication like this is also referred to as the [**dot product**](https://www.mathsisfun.com/algebra/vectors-dot-product.html) of two matrices.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA64Z4DmkB31"
      },
      "source": [
        "Neural networks are full of matrix multiplications and dot products.\n",
        "\n",
        "The [`torch.nn.Linear()`](https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html) module (we'll see this in action later on), also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input `x` and a weights matrix `A`.\n",
        "\n",
        "$$\n",
        "y = x\\cdot{A^T} + b\n",
        "$$\n",
        "\n",
        "Where:\n",
        "* `x` is the input to the layer (deep learning is a stack of layers like `torch.nn.Linear()` and others on top of each other).\n",
        "* `A` is the weights matrix created by the layer, this starts out as random numbers that get adjusted as a neural network learns to better represent patterns in the data (notice the \"`T`\", that's because the weights matrix gets transposed).\n",
        "  * **Note:** You might also often see `W` or another letter like `X` used to showcase the weights matrix.\n",
        "* `b` is the bias term used to slightly offset the weights and inputs.\n",
        "* `y` is the output (a manipulation of the input in the hopes to discover patterns in it).\n",
        "\n",
        "This is a linear function (you may have seen something like $y = mx+b$ in high school or elsewhere), and can be used to draw a straight line!\n",
        "\n",
        "Let's play around with a linear layer.\n",
        "\n",
        "Try changing the values of `in_features` and `out_features` below and see what happens.\n",
        "\n",
        "Do you notice anything to do with the shapes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC_MjKW1LX7T",
        "outputId": "910dc19f-b474-4cc8-fe37-02d98a899525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([3, 2])\n",
            "\n",
            "Output:\n",
            "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
            "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
            "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Output shape: torch.Size([3, 6])\n"
          ]
        }
      ],
      "source": [
        "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
        "torch.manual_seed(42)\n",
        "# This uses matrix multiplication\n",
        "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input\n",
        "                         out_features=6) # out_features = describes outer value\n",
        "x = tensor_A\n",
        "output = linear(x)\n",
        "print(f\"Input shape: {x.shape}\\n\")\n",
        "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan dan menggunakan modul linear (torch.nn.Linear) dengan PyTorch untuk melakukan operasi linier pada tensor tensor_A. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.manual_seed(42): Baris ini mengatur seed untuk generator bilangan acak PyTorch. Ini dilakukan untuk membuat hasil yang dihasilkan secara acak dapat direproduksi pada eksekusi yang berulang, sehingga hasil eksperimen dapat diulang dengan seed yang sama.\n",
        "\n",
        "linear = torch.nn.Linear(in_features=2, out_features=6): Baris ini membuat objek linear yang merupakan lapisan linier (linear layer) dengan dua parameter: in_features adalah jumlah fitur input, dan out_features adalah jumlah fitur output. Dalam hal ini, layer linear ini mengubah input 2 dimensi menjadi output 6 dimensi.\n",
        "\n",
        "x = tensor_A: Baris ini mendefinisikan tensor x sebagai tensor input, yang diambil dari tensor_A.\n",
        "\n",
        "output = linear(x): Baris ini menggunakan layer linear (linear) untuk melakukan transformasi linier pada tensor input x dan menyimpan hasilnya di dalam variabel output.\n",
        "\n",
        "print(f\"Input shape: {x.shape}\\n\"): Baris ini mencetak atau menampilkan bentuk (shape) dari tensor input x.\n",
        "\n",
        "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\"): Baris ini mencetak atau menampilkan hasil dari operasi linier (output) dan bentuk (shape) dari hasil tersebut.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan bentuk dan hasil dari operasi linier:\n",
        "Input shape: torch.Size([3, 2])\n",
        "\n",
        "Output:\n",
        "tensor([[ 0.8232,  1.8743, -0.0680, -0.4239,  0.2031, -1.0507],\n",
        "        [ 1.7726,  3.5587, -0.3848, -1.0326,  0.4565, -2.2329],\n",
        "        [ 2.7220,  5.2430, -0.7017, -1.6413,  0.7099, -3.4151]],\n",
        "       grad_fn=<AddmmBackward>)\n",
        "\n",
        "Output shape: torch.Size([3, 6])\n",
        "Ini menunjukkan bentuk dan hasil dari operasi linier pada tensor input x. Output memiliki bentuk (shape) [3, 6], sesuai dengan jumlah fitur output yang ditentukan pada layer linear (out_features=6). Perhatikan bahwa gradient function (grad_fn) juga dicetak, menunjukkan bahwa tensor output memiliki ketergantungan terhadap tensor input dan dapat digunakan untuk perhitungan gradien dalam proses pelatihan model."
      ],
      "metadata": {
        "id": "pElYFvoZHvsU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIGrP5j1pN7j"
      },
      "source": [
        "> **Question:** What happens if you change `in_features` from 2 to 3 above? Does it error? How could you change the shape of the input (`x`) to accomodate to the error? Hint: what did we have to do to `tensor_B` above?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPNF0nMWoGEj"
      },
      "source": [
        "If you've never done it before, matrix multiplication can be a confusing topic at first.\n",
        "\n",
        "But after you've played around with it a few times and even cracked open a few neural networks, you'll notice it's everywhere.\n",
        "\n",
        "Remember, matrix multiplication is all you need.\n",
        "\n",
        "![matrix multiplication is all you need](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_matrix_multiplication_is_all_you_need.jpeg)\n",
        "\n",
        "*When you start digging into neural network layers and building your own, you'll find matrix multiplications everywhere. **Source:** https://marksaroufim.substack.com/p/working-class-deep-learner*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjMmrJOOPv5e"
      },
      "source": [
        "### Finding the min, max, mean, sum, etc (aggregation)\n",
        "\n",
        "Now we've seen a few ways to manipulate tensors, let's run through a few ways to aggregate them (go from more values to less values).\n",
        "\n",
        "First we'll create a tensor and then find the max, min, mean and sum of it.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrFQbe5fP1Rk",
        "outputId": "952dcbbd-6100-4a18-8e69-2fbddfcc2947"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan sebuah tensor menggunakan fungsi torch.arange(). Berikut adalah penjelasan singkat:\n",
        "\n",
        "x = torch.arange(0, 100, 10): Baris ini membuat tensor x dengan menggunakan fungsi torch.arange(). Fungsi ini menghasilkan urutan nilai berdasarkan parameter yang diberikan. Dalam hal ini:\n",
        "\n",
        "start=0: Nilai awal urutan.\n",
        "end=100: Nilai akhir urutan (tidak termasuk).\n",
        "step=10: Selisih antara dua nilai berturut-turut dalam urutan.\n",
        "Jadi, tensor x akan berisi nilai dari 0 hingga 90 (tidak termasuk 100) dengan selisih 10.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari tensor x:\n",
        "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "Ini menunjukkan tensor x dengan nilai-nilai yang dibentuk oleh fungsi torch.arange(). Tensor ini merupakan tensor satu dimensi (vektor) dengan 10 elemen."
      ],
      "metadata": {
        "id": "VPJXWSWeH-9N"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J-wfMdlsEco"
      },
      "source": [
        "Now let's perform some aggregation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5wSP9YKP3Lb",
        "outputId": "e68a29ea-e543-4d7a-c6eb-f48759ce3c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450\n"
          ]
        }
      ],
      "source": [
        "print(f\"Minimum: {x.min()}\")\n",
        "print(f\"Maximum: {x.max()}\")\n",
        "# print(f\"Mean: {x.mean()}\") # this will error\n",
        "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
        "print(f\"Sum: {x.sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas mencetak nilai minimum, maksimum, rata-rata, dan jumlah dari tensor x. Berikut adalah penjelasan singkat:\n",
        "\n",
        "print(f\"Minimum: {x.min()}\"): Baris ini mencetak nilai minimum dari tensor x menggunakan metode min().\n",
        "\n",
        "print(f\"Maximum: {x.max()}\"): Baris ini mencetak nilai maksimum dari tensor x menggunakan metode max().\n",
        "\n",
        "print(f\"Mean: {x.type(torch.float32).mean()}\"): Baris ini mencetak nilai rata-rata dari tensor x. Sebelum melakukan operasi rata-rata, tensor dikonversi ke tipe data float32 menggunakan type(torch.float32) untuk menghindari error karena PyTorch mengharapkan tensor bertipe float untuk operasi rata-rata.\n",
        "\n",
        "print(f\"Sum: {x.sum()}\"): Baris ini mencetak jumlah dari semua elemen dalam tensor x menggunakan metode sum().\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai statistik dari tensor x:\n",
        "Minimum: 0\n",
        "Maximum: 90\n",
        "Mean: 45.0\n",
        "Sum: 450\n",
        "Perhatikan bahwa operasi rata-rata menggunakan .mean() membutuhkan tensor bertipe data float, sehingga perlu melakukan konversi tipe data sebelumnya. Jika mengaktifkan baris yang di-comment (# print(f\"Mean: {x.mean()}\")), akan muncul error karena PyTorch tidak dapat menghitung rata-rata dari tensor dengan tipe data integer secara langsung."
      ],
      "metadata": {
        "id": "v7M02pGfII4V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHoKpsg3sKQE"
      },
      "source": [
        "> **Note:** You may find some methods such as `torch.mean()` require tensors to be in `torch.float32` (the most common) or another specific datatype, otherwise the operation will fail.\n",
        "\n",
        "You can also do the same as above with `torch` methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cr23Y9uP3HO",
        "outputId": "8b0fd6ed-b975-4c04-e52d-d1d5b8f920dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(90), tensor(0), tensor(45.), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan beberapa fungsi PyTorch untuk menghitung statistik dari tensor x, termasuk nilai maksimum, minimum, rata-rata, dan jumlah elemen. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.max(x): Fungsi ini mengembalikan nilai maksimum dari tensor x. Dalam hal ini, mengembalikan sebuah tensor dengan nilai maksimum dan indeks elemen maksimum.\n",
        "\n",
        "torch.min(x): Fungsi ini mengembalikan nilai minimum dari tensor x. Dalam hal ini, mengembalikan sebuah tensor dengan nilai minimum dan indeks elemen minimum.\n",
        "\n",
        "torch.mean(x.type(torch.float32)): Fungsi ini menghitung rata-rata dari tensor x. Sebelum menghitung rata-rata, tensor dikonversi menjadi tipe data float32 untuk menghindari error, karena operasi rata-rata membutuhkan tensor dengan tipe data float.\n",
        "\n",
        "torch.sum(x): Fungsi ini menghitung jumlah dari semua elemen dalam tensor x.\n",
        "\n",
        "Contoh penggunaan masing-masing fungsi dalam sebuah ekspresi:\n",
        "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)\n",
        "Contoh outputnya mungkin akan menunjukkan nilai maksimum, minimum, rata-rata, dan jumlah dari tensor x:\n",
        "(tensor(90), tensor(0), tensor(45.), tensor(450))\n",
        "Ini menunjukkan bahwa nilai maksimum dalam tensor x adalah 90, nilai minimum adalah 0, rata-rata adalah 45, dan jumlah seluruh elemennya adalah 450."
      ],
      "metadata": {
        "id": "IhmOgAJpISOn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7ApCaZjDkvp"
      },
      "source": [
        "### Positional min/max\n",
        "\n",
        "You can also find the index of a tensor where the max or minimum occurs with [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) and [`torch.argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html) respectively.\n",
        "\n",
        "This is helpful incase you just want the position where the highest (or lowest) value is and not the actual value itself (we'll see this in a later section when using the [softmax activation function](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzNBl9JSGlHi",
        "outputId": "bdb393ee-4a2d-46b4-e4fe-3f443748a8e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Index where max value occurs: 8\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"Tensor: {tensor}\")\n",
        "\n",
        "# Returns index of max and min values\n",
        "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
        "print(f\"Index where min value occurs: {tensor.argmin()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan sebuah tensor menggunakan fungsi torch.arange() dan kemudian mengidentifikasi indeks dari nilai maksimum dan minimum dalam tensor tersebut. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor = torch.arange(10, 100, 10): Baris ini membuat tensor tensor dengan menggunakan fungsi torch.arange(). Fungsi ini menghasilkan urutan nilai berdasarkan parameter yang diberikan. Dalam hal ini, tensor tensor akan berisi nilai dari 10 hingga 90 (tidak termasuk 100) dengan selisih 10.\n",
        "\n",
        "print(f\"Tensor: {tensor}\"): Baris ini mencetak nilai dari tensor tensor.\n",
        "\n",
        "print(f\"Index where max value occurs: {tensor.argmax()}\"): Baris ini mencetak indeks dari nilai maksimum dalam tensor tensor menggunakan metode argmax(). Fungsi ini mengembalikan indeks dari elemen dengan nilai maksimum.\n",
        "\n",
        "print(f\"Index where min value occurs: {tensor.argmin()}\"): Baris ini mencetak indeks dari nilai minimum dalam tensor tensor menggunakan metode argmin(). Fungsi ini mengembalikan indeks dari elemen dengan nilai minimum.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan tensor dan indeks dari nilai maksimum dan minimum:\n",
        "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "Index where max value occurs: 8\n",
        "Index where min value occurs: 0\n",
        "Ini menunjukkan bahwa nilai maksimum dalam tensor tensor adalah 90, dan nilai minimum adalah 10. Indeks 8 menunjukkan posisi di mana nilai maksimum (90) ditemukan, dan indeks 0 menunjukkan posisi di mana nilai minimum (10) ditemukan dalam tensor."
      ],
      "metadata": {
        "id": "Ed5tp1MAIcKy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBu33WihOXBk"
      },
      "source": [
        "### Change tensor datatype\n",
        "\n",
        "As mentioned, a common issue with deep learning operations is having your tensors in different datatypes.\n",
        "\n",
        "If one tensor is in `torch.float64` and another is in `torch.float32`, you might run into some errors.\n",
        "\n",
        "But there's a fix.\n",
        "\n",
        "You can change the datatypes of tensors using [`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html) where the `dtype` parameter is the datatype you'd like to use.\n",
        "\n",
        "First we'll create a tensor and check it's datatype (the default is `torch.float32`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY2FEsCAOaLu",
        "outputId": "b96f6e49-5c94-49d7-cc28-8340436502e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# Create a tensor and check its datatype\n",
        "tensor = torch.arange(10., 100., 10.)\n",
        "tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan sebuah tensor menggunakan fungsi torch.arange() dengan menggunakan parameter untuk nilai start, end, dan step yang bertipe float. Setelah itu, kode tersebut mengambil dan mencetak tipe data (dtype) dari tensor tersebut. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor = torch.arange(10., 100., 10.): Baris ini membuat tensor tensor dengan menggunakan fungsi torch.arange(). Dalam hal ini, parameter start=10., end=100., dan step=10. digunakan untuk menghasilkan urutan nilai float dari 10 hingga 90 (tidak termasuk 100) dengan selisih 10.\n",
        "\n",
        "tensor.dtype: Baris ini mengakses properti dtype dari tensor tensor. Properti ini memberikan informasi tentang tipe data (data type) dari tensor.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan tipe data dari tensor tensor:\n",
        "torch.float32\n",
        "Ini menunjukkan bahwa tensor tensor memiliki tipe data float32. Penggunaan tanda desimal (.) pada parameter fungsi torch.arange() menyebabkan tensor yang dihasilkan memiliki tipe data float."
      ],
      "metadata": {
        "id": "hsVosNBYIkZk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR30FHEc92of"
      },
      "source": [
        "Now we'll create another tensor the same as before but change its datatype to `torch.float16`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cac8gRYjOeab",
        "outputId": "a958cdd7-4d24-4cb8-ff1c-b743789a300a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# Create a float16 tensor\n",
        "tensor_float16 = tensor.type(torch.float16)\n",
        "tensor_float16"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan sebuah tensor baru dengan tipe data float16 (torch.float16) yang diperoleh dari tensor sebelumnya (tensor). Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor_float16 = tensor.type(torch.float16): Baris ini membuat tensor baru, tensor_float16, dengan mengonversi tipe data tensor sebelumnya (tensor) menjadi float16 menggunakan metode .type(torch.float16). Metode ini memungkinkan kita untuk mengubah tipe data tensor.\n",
        "\n",
        "tensor_float16: Baris ini mencetak atau menampilkan tensor yang baru dibuat dengan tipe data float16.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari tensor baru dengan tipe data float16:\n",
        "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)\n",
        "Ini menunjukkan bahwa tensor tensor_float16 memiliki nilai yang sama seperti tensor sebelumnya (tensor), tetapi dengan tipe data yang diubah menjadi float16. Perhatikan bahwa float16 memiliki presisi lebih rendah dibandingkan dengan float32 atau float64, sehingga dapat menghemat ruang memori, tetapi dengan tingkat presisi yang lebih rendah."
      ],
      "metadata": {
        "id": "gz41QfRYIsuY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndVlKJZ4-7_5"
      },
      "source": [
        "And we can do something similar to make a `torch.int8` tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yqovld2Oj6s",
        "outputId": "cd4c6a17-e0f6-41dc-b8cd-1d7fd5b62e63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Create a int8 tensor\n",
        "tensor_int8 = tensor.type(torch.int8)\n",
        "tensor_int8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44GxVabar-xe"
      },
      "source": [
        "> **Note:** Different datatypes can be confusing to begin with. But think of it like this, the lower the number (e.g. 32, 16, 8), the less precise a computer stores the value. And with a lower amount of storage, this generally results in faster computation and a smaller overall model. Mobile-based neural networks often operate with 8-bit integers, smaller and faster to run but less accurate than their float32 counterparts. For more on this, I'd read up about [precision in computing](https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
        "\n",
        "> **Exercise:** So far we've covered a fair few tensor methods but there's a bunch more in the [`torch.Tensor` documentation](https://pytorch.org/docs/stable/tensors.html), I'd recommend spending 10-minutes scrolling through and looking into any that catch your eye. Click on them and then write them out in code yourself to see what happens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CkCtAYmGsHY"
      },
      "source": [
        "### Reshaping, stacking, squeezing and unsqueezing\n",
        "\n",
        "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
        "\n",
        "To do so, some popular methods are:\n",
        "\n",
        "| Method | One-line description |\n",
        "| ----- | ----- |\n",
        "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Reshapes `input` to `shape` (if compatible), can also use `torch.Tensor.reshape()`. |\n",
        "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Returns a view of the original tensor in a different `shape` but shares the same data as the original tensor. |\n",
        "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatenates a sequence of `tensors` along a new dimension (`dim`), all `tensors` must be same size. |\n",
        "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Squeezes `input` to remove all the dimenions with value `1`. |\n",
        "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Returns `input` with a dimension value of `1` added at `dim`. |\n",
        "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Returns a *view* of the original `input` with its dimensions permuted (rearranged) to `dims`. |\n",
        "\n",
        "Why do any of these?\n",
        "\n",
        "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors.\n",
        "\n",
        "Let's try them out.\n",
        "\n",
        "First, we'll create a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYjRTLOzG4Ev",
        "outputId": "5f82be66-494c-4dff-af4c-1414b295f92e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 8.)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan sebuah tensor baru dengan tipe data int8 (torch.int8) yang diperoleh dari tensor sebelumnya (tensor). Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor_int8 = tensor.type(torch.int8): Baris ini membuat tensor baru, tensor_int8, dengan mengonversi tipe data tensor sebelumnya (tensor) menjadi int8 menggunakan metode .type(torch.int8). Metode ini memungkinkan kita untuk mengubah tipe data tensor.\n",
        "\n",
        "tensor_int8: Baris ini mencetak atau menampilkan tensor yang baru dibuat dengan tipe data int8.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari tensor baru dengan tipe data int8:\n",
        "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)\n",
        "Ini menunjukkan bahwa tensor tensor_int8 memiliki nilai yang sama seperti tensor sebelumnya (tensor), tetapi dengan tipe data yang diubah menjadi int8. Perlu diingat bahwa int8 memiliki rentang nilai yang terbatas (dari -128 hingga 127) dan dapat membatasi representasi nilai jika nilai di luar rentang tersebut. Sebagai contoh, nilai-nilai di luar rentang tersebut akan diatur ke nilai maksimum atau minimum yang valid."
      ],
      "metadata": {
        "id": "iMxMlEyEI2u-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_VarMO9CoT8"
      },
      "source": [
        "Now let's add an extra dimension with `torch.reshape()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US4WjpQ3SG-8",
        "outputId": "9057597a-51d9-48ca-8a52-a29a3302e1c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(1, 7)\n",
        "x_reshaped, x_reshaped.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan sebuah tensor menggunakan fungsi torch.arange() dengan parameter start=1. dan end=8.. Setelah itu, kode tersebut mencetak nilai dari tensor tersebut (x) serta bentuknya (shape). Berikut adalah penjelasan singkat:\n",
        "\n",
        "import torch: Import library PyTorch untuk digunakan dalam kode.\n",
        "\n",
        "x = torch.arange(1., 8.): Baris ini membuat tensor x dengan menggunakan fungsi torch.arange(). Dalam hal ini, parameter start=1. dan end=8. digunakan untuk menghasilkan urutan nilai float dari 1 hingga 7 (tidak termasuk 8).\n",
        "\n",
        "x: Baris ini mencetak atau menampilkan nilai dari tensor x.\n",
        "\n",
        "x.shape: Baris ini mengakses properti shape dari tensor x. Properti ini memberikan informasi tentang bentuk (shape) dari tensor.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dan bentuk dari tensor x:\n",
        "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))\n",
        "Ini menunjukkan bahwa tensor x memiliki nilai dari 1 hingga 7 dan bentuknya adalah [7], menunjukkan bahwa tensor ini adalah tensor satu dimensi (vektor) dengan panjang 7 elemen."
      ],
      "metadata": {
        "id": "KMDfhKn3I-s5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tig5xm0jCxuU"
      },
      "source": [
        "We can also change the view with `torch.view()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDN2BNe5TGfB",
        "outputId": "63c25484-821b-40df-bde2-63abc743f26c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# Change view (keeps same data as original but changes view)\n",
        "# See more: https://stackoverflow.com/a/54507446/7900723\n",
        "z = x.view(1, 7)\n",
        "z, z.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan metode view() pada tensor x untuk mengubah tampilan atau bentuk tensor tersebut. Berikut adalah penjelasan singkat:\n",
        "\n",
        "z = x.view(1, 7): Baris ini menggunakan metode view() untuk membuat tensor baru z dengan bentuk (shape) baru [1, 7]. Metode ini memungkinkan kita untuk mengubah tampilan tensor tanpa mengubah data yang sebenarnya. Dalam hal ini, z menjadi tensor dengan satu baris dan tujuh kolom.\n",
        "\n",
        "z: Baris ini mencetak atau menampilkan nilai dari tensor yang baru dibuat, yaitu z.\n",
        "\n",
        "z.shape: Baris ini mengakses properti shape dari tensor z. Properti ini memberikan informasi tentang bentuk (shape) dari tensor.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dan bentuk dari tensor z:\n",
        "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))\n",
        "Ini menunjukkan bahwa tensor z memiliki nilai yang sama dengan tensor x, tetapi bentuknya telah diubah menjadi [1, 7], menunjukkan bahwa sekarang ini adalah tensor dua dimensi dengan satu baris dan tujuh kolom. Konsep ini disebut sebagai \"view\" atau \"reshape\", di mana kita mempertahankan data yang sama tetapi mengubah cara kita melihat atau mengakses tensor tersebut."
      ],
      "metadata": {
        "id": "bZzd2dPWJDMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y78PfjbhI9sz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8joAaUEC2NX"
      },
      "source": [
        "Remember though, changing the view of a tensor with `torch.view()` really only creates a new view of the *same* tensor.\n",
        "\n",
        "So changing the view changes the original tensor too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DxURVvXTGfC",
        "outputId": "bf062f9c-623d-4d32-9ad8-688deaad9b7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# Changing z changes x\n",
        "z[:, 0] = 5\n",
        "z, x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menunjukkan bahwa ketika kita melakukan perubahan pada tensor z, perubahan tersebut juga tercermin pada tensor x, dan sebaliknya. Hal ini terjadi karena tensor z menggunakan tampilan yang sama dengan tensor x. Berikut adalah penjelasan singkat:\n",
        "\n",
        "z[:, 0] = 5: Baris ini mengganti nilai elemen pertama (kolom 0) dari tensor z dengan nilai 5. Notasi [:, 0] mengindikasikan bahwa kita mengganti seluruh baris untuk kolom dengan indeks 0.\n",
        "\n",
        "z: Baris ini mencetak atau menampilkan nilai dari tensor z setelah perubahan.\n",
        "\n",
        "x: Baris ini mencetak atau menampilkan nilai dari tensor x.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai setelah perubahan pada tensor z dan x:\n",
        "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))\n",
        "Ini menunjukkan bahwa ketika kita mengubah nilai elemen pertama dari tensor z menjadi 5, nilai yang sama juga muncul pada tensor x. Hal ini terjadi karena keduanya menggunakan tampilan yang sama terhadap data yang sama. Jadi, perubahan pada satu tensor juga memengaruhi tensor yang lain."
      ],
      "metadata": {
        "id": "NoanrhKMJM7k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxnqDBlpDDJ_"
      },
      "source": [
        "If we wanted to stack our new tensor on top of itself five times, we could do so with `torch.stack()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX5Adf3ORiTK",
        "outputId": "d99b8506-5b5d-4fe8-b1ae-70c20bdcd079"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
        "x_stacked"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan fungsi torch.stack() untuk menggabungkan beberapa tensor ke dalam satu tensor yang baru dengan menumpuknya secara vertikal (dalam dimensi tertentu). Berikut adalah penjelasan singkat:\n",
        "\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0): Baris ini menggunakan fungsi torch.stack() untuk membuat tensor baru x_stacked dengan menumpuk tensor x sebanyak empat kali secara vertikal. Parameter dim=0 menunjukkan bahwa penumpukan dilakukan dalam dimensi pertama (baris).\n",
        "\n",
        "Jika dim diubah menjadi dim=1, penumpukan akan dilakukan dalam dimensi kedua (kolom), sehingga tensor akan menjadi horizontal.\n",
        "x_stacked: Baris ini mencetak atau menampilkan nilai dari tensor x_stacked yang baru dibuat.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari tensor x_stacked:\n",
        "tensor([[1., 2., 3., 4., 5., 6., 7.],\n",
        "        [1., 2., 3., 4., 5., 6., 7.],\n",
        "        [1., 2., 3., 4., 5., 6., 7.],\n",
        "        [1., 2., 3., 4., 5., 6., 7.]])\n",
        "Ini menunjukkan bahwa tensor x_stacked terdiri dari empat salinan tensor x yang ditumpuk secara vertikal dalam dimensi pertama (baris). Setiap baris menunjukkan salinan dari tensor x. Jika parameter dim diubah menjadi dim=1, penumpukan akan dilakukan dalam dimensi kedua (kolom), sehingga tensor akan menjadi horizontal."
      ],
      "metadata": {
        "id": "irn0kTzzJVOB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET56QzNHDuOI"
      },
      "source": [
        "How about removing all single dimensions from a tensor?\n",
        "\n",
        "To do so you can use `torch.squeeze()` (I remember this as *squeezing* the tensor to only have dimensions over 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2Y2HEoDRxJZ",
        "outputId": "8f1d7fb3-0c29-4838-e4a1-530122bbe554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
            "Previous shape: torch.Size([1, 7])\n",
            "\n",
            "New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "New shape: torch.Size([7])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimension from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menunjukkan operasi untuk menghilangkan dimensi yang tidak diperlukan dari tensor menggunakan metode squeeze(). Berikut adalah penjelasan singkat:\n",
        "\n",
        "print(f\"Previous tensor: {x_reshaped}\"): Baris ini mencetak nilai dari tensor sebelum operasi penghilangan dimensi, yaitu tensor x_reshaped.\n",
        "\n",
        "print(f\"Previous shape: {x_reshaped.shape}\"): Baris ini mencetak bentuk (shape) dari tensor sebelum operasi penghilangan dimensi, yaitu bentuk tensor x_reshaped.\n",
        "\n",
        "x_squeezed = x_reshaped.squeeze(): Baris ini menggunakan metode squeeze() untuk menghasilkan tensor baru x_squeezed dengan menghilangkan dimensi yang memiliki panjang 1. Metode ini secara otomatis menghilangkan dimensi yang tidak diperlukan.\n",
        "\n",
        "print(f\"\\nNew tensor: {x_squeezed}\"): Baris ini mencetak nilai dari tensor setelah operasi penghilangan dimensi, yaitu tensor x_squeezed.\n",
        "\n",
        "print(f\"New shape: {x_squeezed.shape}\"): Baris ini mencetak bentuk (shape) dari tensor setelah operasi penghilangan dimensi, yaitu bentuk tensor x_squeezed.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dan bentuk sebelum dan setelah penghilangan dimensi:\n",
        "Previous tensor: tensor([[1.],\n",
        "        [2.],\n",
        "        [3.],\n",
        "        [4.],\n",
        "        [5.],\n",
        "        [6.],\n",
        "        [7.]])\n",
        "Previous shape: torch.Size([7, 1])\n",
        "\n",
        "New tensor: tensor([1., 2., 3., 4., 5., 6., 7.])\n",
        "New shape: torch.Size([7])\n",
        "Ini menunjukkan bahwa tensor x_reshaped sebelumnya memiliki bentuk [7, 1] (tensor kolom), dan setelah operasi squeeze(), dimensi dengan panjang 1 dihilangkan sehingga tensor x_squeezed memiliki bentuk [7] (tensor satu dimensi atau vektor)."
      ],
      "metadata": {
        "id": "TD-7vnfUJfOC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acjDLk8WD8NC"
      },
      "source": [
        "And to do the reverse of `torch.squeeze()` you can use `torch.unsqueeze()` to add a dimension value of 1 at a specific index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUC-DEEwSYv7",
        "outputId": "01691b71-f1ac-42dd-dc34-6e7a2ab4c3e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "Previous shape: torch.Size([7])\n",
            "\n",
            "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
            "New shape: torch.Size([1, 7])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Previous tensor: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "## Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menunjukkan operasi untuk menambahkan dimensi tambahan ke dalam tensor menggunakan metode unsqueeze(). Berikut adalah penjelasan singkat:\n",
        "\n",
        "print(f\"Previous tensor: {x_squeezed}\"): Baris ini mencetak nilai dari tensor sebelum operasi penambahan dimensi, yaitu tensor x_squeezed.\n",
        "\n",
        "print(f\"Previous shape: {x_squeezed.shape}\"): Baris ini mencetak bentuk (shape) dari tensor sebelum operasi penambahan dimensi, yaitu bentuk tensor x_squeezed.\n",
        "\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0): Baris ini menggunakan metode unsqueeze() untuk menambahkan dimensi tambahan ke dalam tensor x_squeezed. Parameter dim=0 menunjukkan bahwa dimensi baru akan ditambahkan di posisi pertama (sebagai dimensi pertama).\n",
        "\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\"): Baris ini mencetak nilai dari tensor setelah operasi penambahan dimensi, yaitu tensor x_unsqueezed.\n",
        "\n",
        "print(f\"New shape: {x_unsqueezed.shape}\"): Baris ini mencetak bentuk (shape) dari tensor setelah operasi penambahan dimensi, yaitu bentuk tensor x_unsqueezed.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dan bentuk sebelum dan setelah penambahan dimensi:\n",
        "Previous tensor: tensor([1., 2., 3., 4., 5., 6., 7.])\n",
        "Previous shape: torch.Size([7])\n",
        "\n",
        "New tensor: tensor([[1., 2., 3., 4., 5., 6., 7.]])\n",
        "New shape: torch.Size([1, 7])\n",
        "Ini menunjukkan bahwa tensor x_squeezed sebelumnya memiliki bentuk [7] (tensor satu dimensi atau vektor), dan setelah operasi unsqueeze(), dimensi baru dengan panjang 1 ditambahkan sehingga tensor x_unsqueezed memiliki bentuk [1, 7] (tensor dengan satu baris dan tujuh kolom)."
      ],
      "metadata": {
        "id": "JDb-Y66CJoAw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9DuJzXgFbM5"
      },
      "source": [
        "You can also rearrange the order of axes values with `torch.permute(input, dims)`, where the `input` gets turned into a *view* with new `dims`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCRGCX8DTGfC",
        "outputId": "f8194503-f972-42a4-dc19-8b0c19464c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# Create tensor with specific shape\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# Permute the original tensor to rearrange the axis order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan sebuah tensor dengan bentuk (shape) tertentu, kemudian menggunakan metode permute() untuk menukar urutan sumbu atau dimensi tensor. Berikut adalah penjelasan singkat:\n",
        "\n",
        "x_original = torch.rand(size=(224, 224, 3)): Baris ini menciptakan tensor x_original dengan menggunakan fungsi torch.rand() untuk menghasilkan nilai acak dengan bentuk (shape) [224, 224, 3]. Ini bisa diasumsikan sebagai gambar dengan lebar 224 piksel, tinggi 224 piksel, dan 3 saluran warna (RGB).\n",
        "\n",
        "x_permuted = x_original.permute(2, 0, 1): Baris ini menggunakan metode permute() untuk menukar urutan sumbu atau dimensi tensor. Dalam hal ini, dimensi 0 dipindahkan ke dimensi 1, dimensi 1 dipindahkan ke dimensi 2, dan dimensi 2 dipindahkan ke dimensi 0. Ini sering digunakan dalam konteks pengolahan gambar untuk mengubah urutan sumbu agar sesuai dengan format yang diinginkan.\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\"): Baris ini mencetak bentuk (shape) dari tensor x_original sebelum operasi pemutaran dimensi.\n",
        "\n",
        "print(f\"New shape: {x_permuted.shape}\"): Baris ini mencetak bentuk (shape) dari tensor x_permuted setelah operasi pemutaran dimensi.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan bentuk sebelum dan setelah pemutaran dimensi:\n",
        "Previous shape: torch.Size([224, 224, 3])\n",
        "New shape: torch.Size([3, 224, 224])\n",
        "Ini menunjukkan bahwa tensor x_original memiliki bentuk [224, 224, 3], dan setelah operasi permute(), dimensi atau sumbu dari tensor x_permuted telah diubah menjadi [3, 224, 224]. Ini berguna, misalnya, ketika bekerja dengan model jaringan saraf yang memerlukan format input khusus."
      ],
      "metadata": {
        "id": "RLCdvWjNJxNx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06LKaFemGBoE"
      },
      "source": [
        "> **Note**: Because permuting returns a *view* (shares the same data as the original), the values in the permuted tensor will be the same as the original tensor and if you change the values in the view, it will change the values of the original."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEPqVL7fTGfC"
      },
      "source": [
        "## Indexing (selecting data from tensors)\n",
        "\n",
        "Sometimes you'll want to select specific data from tensors (for example, only the first column or second row).\n",
        "\n",
        "To do so, you can use indexing.\n",
        "\n",
        "If you've ever done indexing on Python lists or NumPy arrays, indexing in PyTorch with tensors is very similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSXzdxCQTGfD",
        "outputId": "3e34ba3c-1edd-4142-9ce2-02663f5b3e9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas membuat sebuah tensor menggunakan fungsi torch.arange() untuk membuat urutan nilai dari 1 hingga 9, dan kemudian menggunakan metode reshape() untuk mengubah bentuk atau dimensi tensor. Berikut adalah penjelasan singkat:\n",
        "\n",
        "import torch: Baris ini mengimpor library PyTorch untuk digunakan dalam kode.\n",
        "\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3): Baris ini membuat tensor x dengan menggunakan fungsi torch.arange() untuk menghasilkan urutan nilai dari 1 hingga 9. Selanjutnya, metode reshape(1, 3, 3) digunakan untuk mengubah bentuk tensor menjadi matriks 3x3 dan menambahkan dimensi ekstra di depannya (dimensi pertama menjadi 1). Jadi, bentuk akhirnya adalah [1, 3, 3].\n",
        "\n",
        "x: Baris ini mencetak atau menampilkan nilai dari tensor x.\n",
        "\n",
        "x.shape: Baris ini mengakses properti shape dari tensor x, yang memberikan informasi tentang bentuk (shape) dari tensor.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dan bentuk dari tensor x:\n",
        "(tensor([[[1, 2, 3],\n",
        "          [4, 5, 6],\n",
        "          [7, 8, 9]]]),\n",
        " torch.Size([1, 3, 3]))\n",
        "Ini menunjukkan bahwa tensor x memiliki nilai dari 1 hingga 9 dan bentuk [1, 3, 3], yang berarti tensor ini adalah tensor tiga dimensi dengan satu salinan matriks 3x3."
      ],
      "metadata": {
        "id": "TNkuVvZ2J5pW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQG5krnKG43B"
      },
      "source": [
        "Indexing values goes outer dimension -> inner dimension (check out the square brackets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv_Z3IAzTGfD",
        "outputId": "b45acfa0-1689-4945-abe8-0a1605297146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First square bracket:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Second square bracket: tensor([1, 2, 3])\n",
            "Third square bracket: 1\n"
          ]
        }
      ],
      "source": [
        "# Let's index bracket by bracket\n",
        "print(f\"First square bracket:\\n{x[0]}\")\n",
        "print(f\"Second square bracket: {x[0][0]}\")\n",
        "print(f\"Third square bracket: {x[0][0][0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan indeksing untuk mengakses elemen dari tensor x. Berikut adalah penjelasan singkat:\n",
        "\n",
        "print(f\"First square bracket:\\n{x[0]}\"): Baris ini mencetak atau menampilkan hasil indeksing pertama dari tensor x. Dengan menggunakan indeks [0], kita mengakses elemen pertama dari tensor x, yang dalam hal ini adalah seluruh matriks 3x3.\n",
        "\n",
        "print(f\"Second square bracket: {x[0][0]}\"): Baris ini mencetak atau menampilkan hasil indeksing kedua dari tensor x. Dengan menggunakan indeks [0][0], kita mengakses elemen pertama dari matriks yang telah diakses pada langkah sebelumnya, sehingga kita mendapatkan baris pertama dari matriks tersebut.\n",
        "\n",
        "print(f\"Third square bracket: {x[0][0][0]}\"): Baris ini mencetak atau menampilkan hasil indeksing ketiga dari tensor x. Dengan menggunakan indeks [0][0][0], kita mengakses elemen pertama dari baris pertama dari matriks yang telah diakses pada langkah sebelumnya, sehingga kita mendapatkan elemen pertama dari tensor awal.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari setiap langkah indeksing:\n",
        "First square bracket:\n",
        "tensor([[1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]])\n",
        "Second square bracket: tensor([1, 2, 3])\n",
        "Third square bracket: 1\n",
        "Ini menunjukkan bahwa melalui langkah-langkah indeksing, kita dapat mengakses elemen-elemen spesifik dari tensor."
      ],
      "metadata": {
        "id": "qTkpfqOqKEEs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaLjaIFxHe89"
      },
      "source": [
        "You can also use `:` to specify \"all values in this dimension\" and then use a comma (`,`) to add another dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCT09pqeTGfD",
        "outputId": "a45aaa06-9692-442d-e622-9f1d27f14d68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
        "x[:, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan slicing untuk mengakses sebagian dari tensor x. Dalam hal ini, kita ingin mendapatkan semua nilai dari dimensi ke-0 dan indeks ke-0 dari dimensi ke-1. Berikut adalah penjelasan singkat:\n",
        "\n",
        "x[:, 0]: Baris ini menggunakan slicing untuk mendapatkan sebagian dari tensor x. Slicing dilakukan dengan menggunakan : pada dimensi ke-0, yang berarti kita ingin mengambil semua nilai dari dimensi tersebut. Selanjutnya, menggunakan indeks 0 pada dimensi ke-1, kita ingin mendapatkan nilai pada indeks ke-0 dari setiap array di dalam dimensi ke-1.\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari hasil slicing:\n",
        "tensor([[1, 2, 3]])\n",
        "Ini menunjukkan bahwa kita mendapatkan baris pertama dari tensor x, yaitu [1, 2, 3], yang sesuai dengan indeks ke-0 dari setiap array di dalam dimensi ke-1."
      ],
      "metadata": {
        "id": "bJhIDD9rKMNQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwDx_gMsTGfD",
        "outputId": "c2c0c285-57ae-4e44-ddc1-d4317ac1927e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
        "x[:, :, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan slicing untuk mengakses sebagian dari tensor x. Dalam hal ini, kita ingin mendapatkan semua nilai dari dimensi ke-0 dan ke-1, tetapi hanya indeks ke-1 dari dimensi ke-2. Berikut adalah penjelasan singkat:\n",
        "\n",
        "x[:, :, 1]: Baris ini menggunakan slicing untuk mendapatkan sebagian dari tensor x.\n",
        ": pada dimensi ke-0 dan ke-1 berarti kita ingin mengambil semua nilai dari dimensi tersebut.\n",
        "1 pada dimensi ke-2 berarti kita hanya ingin mengambil nilai pada indeks ke-1 dari setiap array di dalam dimensi ke-2.\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari hasil slicing:\n",
        "tensor([[2],\n",
        "        [5],\n",
        "        [8]])\n",
        "Ini menunjukkan bahwa kita mendapatkan kolom kedua dari setiap matriks di dalam dimensi ke-2, yang sesuai dengan indeks ke-1 dari dimensi tersebut. Sebagai contoh, kita mendapatkan nilai [2, 5, 8] dari kolom kedua."
      ],
      "metadata": {
        "id": "v5VRJhT9KUYs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiw3_1E3TGfD",
        "outputId": "0d1fb756-f0d1-4994-e59c-effcd7a831be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
        "x[:, 1, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan slicing untuk mengakses sebagian dari tensor x. Dalam hal ini, kita ingin mendapatkan semua nilai dari dimensi ke-0, tetapi hanya nilai pada indeks ke-1 dari dimensi ke-1 dan ke-2. Berikut adalah penjelasan singkat:\n",
        "\n",
        "x[:, 1, 1]: Baris ini menggunakan slicing untuk mendapatkan sebagian dari tensor x.\n",
        ": pada dimensi ke-0 berarti kita ingin mengambil semua nilai dari dimensi tersebut.\n",
        "1 pada dimensi ke-1 berarti kita hanya ingin mengambil nilai pada indeks ke-1 dari dimensi tersebut.\n",
        "1 pada dimensi ke-2 berarti kita hanya ingin mengambil nilai pada indeks ke-1 dari dimensi tersebut.\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari hasil slicing:\n",
        "tensor([5])\n",
        "Ini menunjukkan bahwa kita mendapatkan nilai pada indeks ke-1 dari dimensi ke-1 dan ke-2, tetapi semua nilai dari dimensi ke-0. Sebagai contoh, kita mendapatkan nilai 5 yang merupakan nilai pada indeks ke-1 dari dimensi ke-1 dan ke-2 pada tensor x."
      ],
      "metadata": {
        "id": "gIZ48bi9KkoA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFVEgrKhTGfD",
        "outputId": "fcd5032f-ce8d-4e98-d724-388ff15db8ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "x[0, 0, :] # same as x[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan indeksing untuk mengakses sebagian dari tensor x. Dalam hal ini, kita ingin mendapatkan nilai pada indeks ke-0 dari dimensi ke-0 dan ke-1, tetapi semua nilai dari dimensi ke-2. Berikut adalah penjelasan singkat:\n",
        "\n",
        "x[0, 0, :]: Baris ini menggunakan indeksing untuk mendapatkan sebagian dari tensor x.\n",
        "0 pada dimensi ke-0 dan ke-1 berarti kita ingin mengambil nilai pada indeks ke-0 dari kedua dimensi tersebut.\n",
        ": pada dimensi ke-2 berarti kita ingin mengambil semua nilai dari dimensi tersebut.\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari hasil indeksing:\n",
        "tensor([1, 2, 3])\n",
        "Ini menunjukkan bahwa kita mendapatkan nilai pada indeks ke-0 dari dimensi ke-0 dan ke-1, tetapi semua nilai dari dimensi ke-2. Dalam hal ini, kita mendapatkan nilai [1, 2, 3] yang merupakan nilai pada indeks ke-0 dari dimensi ke-0 dan ke-1 pada tensor x. Juga, perlu dicatat bahwa x[0, 0, :] ekuivalen dengan x[0][0], yaitu cara lain untuk mencapai hasil yang sama."
      ],
      "metadata": {
        "id": "oQlLbNCnLBjb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ik0r11RIxtm"
      },
      "source": [
        "Indexing can be quite confusing to begin with, especially with larger tensors (I still have to try indexing multiple times to get it right). But with a bit of practice and following the data explorer's motto (***visualize, visualize, visualize***), you'll start to get the hang of it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8ZaW0Bq7rCm"
      },
      "source": [
        "## PyTorch tensors & NumPy\n",
        "\n",
        "Since NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.  \n",
        "\n",
        "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
        "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - NumPy array -> PyTorch tensor.\n",
        "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - PyTorch tensor -> NumPy array.\n",
        "\n",
        "Let's try them out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDrDCnvY7rKS",
        "outputId": "f67abc00-267d-4aa6-acfc-f91cd49b19ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# NumPy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas mengilustrasikan cara mengonversi array NumPy menjadi tensor PyTorch. Berikut adalah penjelasan singkat:\n",
        "\n",
        "import torch dan import numpy as np: Baris ini mengimpor library PyTorch dan NumPy untuk digunakan dalam kode.\n",
        "\n",
        "array = np.arange(1.0, 8.0): Baris ini membuat array NumPy menggunakan fungsi np.arange() untuk menghasilkan urutan nilai dari 1.0 hingga 7.0. Nilai 8.0 tidak termasuk dalam array.\n",
        "\n",
        "tensor = torch.from_numpy(array): Baris ini menggunakan fungsi torch.from_numpy() untuk mengonversi array NumPy menjadi tensor PyTorch. Tensor yang dihasilkan akan memiliki tipe data yang sesuai dengan tipe data array NumPy.\n",
        "\n",
        "array: Baris ini mencetak atau menampilkan nilai dari array NumPy.\n",
        "\n",
        "tensor: Baris ini mencetak atau menampilkan nilai dari tensor PyTorch yang dihasilkan.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari array NumPy dan tensor PyTorch:\n",
        "(array([1., 2., 3., 4., 5., 6., 7.]), tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))\n",
        "Ini menunjukkan bahwa array NumPy [1., 2., 3., 4., 5., 6., 7.] telah berhasil dikonversi menjadi tensor PyTorch dengan tipe data torch.float64. Konversi ini berguna ketika kita ingin bekerja dengan data dalam format tensor PyTorch dalam konteks penggunaan PyTorch."
      ],
      "metadata": {
        "id": "3cBUjBBHLZ0e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16JG6cONLPnO"
      },
      "source": [
        "> **Note:** By default, NumPy arrays are created with the datatype `float64` and if you convert it to a PyTorch tensor, it'll keep the same datatype (as above).\n",
        ">\n",
        "> However, many PyTorch calculations default to using `float32`.\n",
        ">\n",
        "> So if you want to convert your NumPy array (float64) -> PyTorch tensor (float64) -> PyTorch tensor (float32), you can use `tensor = torch.from_numpy(array).type(torch.float32)`.\n",
        "\n",
        "Because we reassigned `tensor` above, if you change the tensor, the array stays the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovwl7VCREv8L",
        "outputId": "9f65cb94-8895-4ad8-bd9a-e187e28ff14c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# Change the array, keep the tensor\n",
        "array = array + 1\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menunjukkan pengaruh perubahan pada array NumPy terhadap tensor PyTorch yang dihasilkan sebelumnya melalui fungsi torch.from_numpy(). Berikut adalah penjelasan singkat:\n",
        "\n",
        "array = array + 1: Baris ini menambahkan nilai 1 ke setiap elemen dalam array NumPy. Ini adalah operasi yang dilakukan pada array NumPy.\n",
        "\n",
        "array: Baris ini mencetak atau menampilkan nilai dari array NumPy setelah dilakukan penambahan.\n",
        "\n",
        "tensor: Baris ini mencetak atau menampilkan nilai dari tensor PyTorch yang dihasilkan sebelumnya.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari array NumPy dan tensor PyTorch setelah perubahan array:\n",
        "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))\n",
        "Perhatikan bahwa nilai tensor PyTorch tetap tidak berubah meskipun ada perubahan pada array NumPy. Fungsi torch.from_numpy() tidak membuat salinan data, tetapi berbagi memori antara array NumPy dan tensor PyTorch. Oleh karena itu, perubahan pada array NumPy dapat tercermin dalam tensor PyTorch. Jika Anda ingin menghindari perubahan ini, Anda dapat membuat salinan tensor dengan menggunakan tensor.clone() atau torch.tensor(array)."
      ],
      "metadata": {
        "id": "QNrCYCAWLrN_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geVvu1p0MTWc"
      },
      "source": [
        "And if you want to go from PyTorch tensor to NumPy array, you can call `tensor.numpy()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw_7ZyVaTKxQ",
        "outputId": "00afdabf-a6a1-427b-9496-3edb6bd494c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
        "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menunjukkan cara mengonversi tensor PyTorch menjadi array NumPy. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor = torch.ones(7): Baris ini membuat tensor PyTorch yang berisi tujuh elemen dengan nilai satu. Tensor ini memiliki tipe data default float32.\n",
        "\n",
        "numpy_tensor = tensor.numpy(): Baris ini menggunakan metode numpy() untuk mengonversi tensor PyTorch tensor menjadi array NumPy numpy_tensor. Perlu diingat bahwa kedua objek (tensor dan array) akan berbagi memori, yang berarti perubahan pada salah satu dari mereka akan tercermin pada yang lainnya.\n",
        "\n",
        "tensor: Baris ini mencetak atau menampilkan nilai dari tensor PyTorch.\n",
        "\n",
        "numpy_tensor: Baris ini mencetak atau menampilkan nilai dari array NumPy yang dihasilkan dari tensor PyTorch.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari tensor PyTorch dan array NumPy:\n",
        "(tensor([1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))\n",
        "Ini menunjukkan bahwa tensor PyTorch [1., 1., 1., 1., 1., 1., 1.] telah berhasil dikonversi menjadi array NumPy dengan tipe data float32. Jika terdapat perubahan pada tensor PyTorch, perubahan tersebut juga akan tercermin pada array NumPy karena keduanya berbagi memori."
      ],
      "metadata": {
        "id": "i2R1EA8mL0W1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt8yEV1jMfi2"
      },
      "source": [
        "And the same rule applies as above, if you change the original `tensor`, the new `numpy_tensor` stays the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMp6ZSkET4_Y",
        "outputId": "c813e1ac-4d57-41bc-f212-1a380b86e851"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# Change the tensor, keep the array the same\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menunjukkan pengaruh perubahan pada tensor PyTorch terhadap array NumPy yang dihasilkan sebelumnya melalui fungsi tensor.numpy(). Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor = tensor + 1: Baris ini menambahkan nilai 1 ke setiap elemen dalam tensor PyTorch. Ini adalah operasi yang dilakukan pada tensor PyTorch.\n",
        "\n",
        "tensor: Baris ini mencetak atau menampilkan nilai dari tensor PyTorch setelah dilakukan penambahan.\n",
        "\n",
        "numpy_tensor: Baris ini mencetak atau menampilkan nilai dari array NumPy yang dihasilkan sebelumnya.\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai dari tensor PyTorch dan array NumPy setelah perubahan tensor:\n",
        "(tensor([2., 2., 2., 2., 2., 2., 2.]), array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))\n",
        "Perhatikan bahwa nilai tensor PyTorch berubah setelah penambahan, tetapi nilai array NumPy tetap tidak berubah. Meskipun keduanya berbagi memori, perubahan pada tensor PyTorch tidak tercermin pada array NumPy. Hal ini karena konversi dari tensor PyTorch ke array NumPy menggunakan fungsi numpy() membuat salinan data, sehingga perubahan pada tensor tidak mempengaruhi array yang sudah dihasilkan."
      ],
      "metadata": {
        "id": "21M5cyGDL9uz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gU3ubCrUkI-"
      },
      "source": [
        "## Reproducibility (trying to take the random out of random)\n",
        "\n",
        "As you learn more about neural networks and machine learning, you'll start to discover how much randomness plays a part.\n",
        "\n",
        "Well, pseudorandomness that is. Because after all, as they're designed, a computer is fundamentally deterministic (each step is predictable) so the randomness they create are simulated randomness (though there is debate on this too, but since I'm not a computer scientist, I'll let you find out more yourself).\n",
        "\n",
        "How does this relate to neural networks and deep learning then?\n",
        "\n",
        "We've discussed neural networks start with random numbers to describe patterns in data (these numbers are poor descriptions) and try to improve those random numbers using tensor operations (and a few other things we haven't discussed yet) to better describe patterns in data.\n",
        "\n",
        "In short:\n",
        "\n",
        "``start with random numbers -> tensor operations -> try to make better (again and again and again)``\n",
        "\n",
        "Although randomness is nice and powerful, sometimes you'd like there to be a little less randomness.\n",
        "\n",
        "Why?\n",
        "\n",
        "So you can perform repeatable experiments.\n",
        "\n",
        "For example, you create an algorithm capable of achieving X performance.\n",
        "\n",
        "And then your friend tries it out to verify you're not crazy.\n",
        "\n",
        "How could they do such a thing?\n",
        "\n",
        "That's where **reproducibility** comes in.\n",
        "\n",
        "In other words, can you get the same (or very similar) results on your computer running the same code as I get on mine?\n",
        "\n",
        "Let's see a brief example of reproducibility in PyTorch.\n",
        "\n",
        "We'll start by creating two random tensors, since they're random, you'd expect them to be different right?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSwxnwEbTGfF",
        "outputId": "277290aa-fb3b-41e1-d195-663d6a7cabcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A:\n",
            "tensor([[0.8016, 0.3649, 0.6286, 0.9663],\n",
            "        [0.7687, 0.4566, 0.5745, 0.9200],\n",
            "        [0.3230, 0.8613, 0.0919, 0.3102]])\n",
            "\n",
            "Tensor B:\n",
            "tensor([[0.9536, 0.6002, 0.0351, 0.6826],\n",
            "        [0.3743, 0.5220, 0.1336, 0.9666],\n",
            "        [0.9754, 0.8474, 0.8988, 0.1105]])\n",
            "\n",
            "Does Tensor A equal Tensor B? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create two random tensors\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
        "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
        "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
        "random_tensor_A == random_tensor_B"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan PyTorch untuk membuat dua tensor acak (random_tensor_A dan random_tensor_B) dan memeriksa apakah keduanya sama dalam hal elemen-elemen mereka. Berikut adalah penjelasan singkat:\n",
        "\n",
        "import torch: Baris ini mengimpor library PyTorch, memungkinkan penggunaan fungsi-fungsi dan struktur data PyTorch.\n",
        "\n",
        "random_tensor_A = torch.rand(3, 4): Baris ini membuat tensor acak random_tensor_A dengan bentuk (shape) 3x4 menggunakan fungsi torch.rand(). Tensor ini akan berisi nilai-nilai acak antara 0 dan 1.\n",
        "\n",
        "random_tensor_B = torch.rand(3, 4): Baris ini membuat tensor acak random_tensor_B dengan bentuk (shape) yang sama seperti random_tensor_A.\n",
        "\n",
        "print(f\"Tensor A:\\n{random_tensor_A}\\n\"): Baris ini mencetak atau menampilkan nilai dari tensor random_tensor_A.\n",
        "\n",
        "print(f\"Tensor B:\\n{random_tensor_B}\\n\"): Baris ini mencetak atau menampilkan nilai dari tensor random_tensor_B.\n",
        "\n",
        "print(f\"Does Tensor A equal Tensor B? (anywhere)\"): Baris ini mencetak atau menampilkan pesan pertanyaan.\n",
        "\n",
        "random_tensor_A == random_tensor_B: Baris ini menggunakan operator perbandingan == untuk memeriksa apakah nilai-nilai elemen dalam random_tensor_A sama dengan nilai-nilai elemen dalam random_tensor_B. Hasilnya adalah tensor boolean yang menunjukkan di mana elemen-elemen tersebut sama (True) atau tidak sama (False).\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai tensor A, nilai tensor B, dan hasil perbandingan:\n",
        "Tensor A:\n",
        "tensor([[0.1234, 0.5678, 0.9101, 0.2345],\n",
        "        [0.6789, 0.4567, 0.7890, 0.1234],\n",
        "        [0.5678, 0.2345, 0.6789, 0.9012]])\n",
        "\n",
        "Tensor B:\n",
        "tensor([[0.9876, 0.5432, 0.1098, 0.7654],\n",
        "        [0.1234, 0.5678, 0.9101, 0.2345],\n",
        "        [0.6789, 0.4567, 0.7890, 0.1234]])\n",
        "\n",
        "Does Tensor A equal Tensor B? (anywhere)\n",
        "tensor([[False, False, False, False],\n",
        "        [False, False, False, False],\n",
        "        [False, False, False, False]])\n",
        "Hasilnya menunjukkan bahwa tidak ada elemen yang sama di antara random_tensor_A dan random_tensor_B, karena hasil perbandingannya adalah False di semua lokasi."
      ],
      "metadata": {
        "id": "YpRq0DZuMJrA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPU6mDKJnr8M"
      },
      "source": [
        "Just as you might've expected, the tensors come out with different values.\n",
        "\n",
        "But what if you wanted to created two random tensors with the *same* values.\n",
        "\n",
        "As in, the tensors would still contain random values but they would be of the same flavour.\n",
        "\n",
        "That's where [`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html) comes in, where `seed` is an integer (like `42` but it could be anything) that flavours the randomness.\n",
        "\n",
        "Let's try it out by creating some more *flavoured* random tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB6d1GfYTGfF",
        "outputId": "2387c771-85a9-4938-cd60-9d1c8fd55d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor C:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Tensor D:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Does Tensor C equal Tensor D? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "# # Set the random seed\n",
        "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
        "torch.manual_seed(seed=RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "# Have to reset the seed every time a new rand() is called\n",
        "# Without this, tensor_D would be different to tensor_C\n",
        "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
        "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
        "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
        "random_tensor_C == random_tensor_D"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan PyTorch untuk membuat dua tensor acak (random_tensor_C dan random_tensor_D) dengan menset seed dari generator angka acak untuk membuat hasil yang dapat direproduksi. Berikut adalah penjelasan singkat:\n",
        "\n",
        "import torch: Baris ini mengimpor library PyTorch, memungkinkan penggunaan fungsi-fungsi dan struktur data PyTorch.\n",
        "\n",
        "import random: Baris ini mengimpor library random, yang akan digunakan untuk mengatur seed dari generator angka acak.\n",
        "\n",
        "RANDOM_SEED = 42: Baris ini mengatur nilai seed yang akan digunakan untuk generator angka acak.\n",
        "\n",
        "torch.manual_seed(seed=RANDOM_SEED): Baris ini mengatur seed untuk generator angka acak PyTorch menggunakan fungsi torch.manual_seed(). Ini memastikan bahwa hasil dari fungsi-fungsi acak PyTorch akan selalu sama jika seed-nya tetap.\n",
        "\n",
        "random_tensor_C = torch.rand(3, 4): Baris ini membuat tensor acak random_tensor_C dengan bentuk (shape) 3x4 menggunakan fungsi torch.rand().\n",
        "\n",
        "torch.random.manual_seed(seed=RANDOM_SEED): Baris ini mengatur seed untuk generator angka acak PyTorch yang digunakan oleh fungsi-fungsi acak lainnya.\n",
        "\n",
        "random_tensor_D = torch.rand(3, 4): Baris ini membuat tensor acak random_tensor_D dengan bentuk (shape) yang sama seperti random_tensor_C. Karena seed-nya diset ulang, tensor ini akan memiliki nilai yang sama dengan random_tensor_C.\n",
        "\n",
        "print(f\"Tensor C:\\n{random_tensor_C}\\n\"): Baris ini mencetak atau menampilkan nilai dari tensor random_tensor_C.\n",
        "\n",
        "print(f\"Tensor D:\\n{random_tensor_D}\\n\"): Baris ini mencetak atau menampilkan nilai dari tensor random_tensor_D.\n",
        "\n",
        "print(f\"Does Tensor C equal Tensor D? (anywhere)\"): Baris ini mencetak atau menampilkan pesan pertanyaan.\n",
        "\n",
        "random_tensor_C == random_tensor_D: Baris ini menggunakan operator perbandingan == untuk memeriksa apakah nilai-nilai elemen dalam random_tensor_C sama dengan nilai-nilai elemen dalam random_tensor_D. Hasilnya adalah tensor boolean yang menunjukkan di mana elemen-elemen tersebut sama (True) atau tidak sama (False).\n",
        "\n",
        "Contoh outputnya mungkin akan menunjukkan nilai tensor C, nilai tensor D, dan hasil perbandingan:\n",
        "Tensor C:\n",
        "tensor([[0.6459, 0.4376, 0.8918, 0.9636],\n",
        "        [0.3832, 0.7917, 0.6607, 0.5734],\n",
        "        [0.2593, 0.8884, 0.8493, 0.7214]])\n",
        "\n",
        "Tensor D:\n",
        "tensor([[0.6459, 0.4376, 0.8918, 0.9636],\n",
        "        [0.3832, 0.7917, 0.6607, 0.5734],\n",
        "        [0.2593, 0.8884, 0.8493, 0.7214]])\n",
        "\n",
        "Does Tensor C equal Tensor D? (anywhere)\n",
        "tensor([[True, True, True, True],\n",
        "        [True, True, True, True],\n",
        "        [True, True, True, True]])\n",
        "Hasilnya menunjukkan bahwa nilai-nilai elemen dalam random_tensor_C dan random_tensor_D sama di semua lokasi, karena seed generator angka acak diset sama untuk keduanya."
      ],
      "metadata": {
        "id": "W2NbwIElMQhj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uct53Xr5QRC_"
      },
      "source": [
        "Nice!\n",
        "\n",
        "It looks like setting the seed worked.\n",
        "\n",
        "> **Resource:** What we've just covered only scratches the surface of reproducibility in PyTorch. For more, on reproducbility in general and random seeds, I'd checkout:\n",
        "> * [The PyTorch reproducibility documentation](https://pytorch.org/docs/stable/notes/randomness.html) (a good exericse would be to read through this for 10-minutes and even if you don't understand it now, being aware of it is important).\n",
        "> * [The Wikipedia random seed page](https://en.wikipedia.org/wiki/Random_seed) (this'll give a good overview of random seeds and pseudorandomness in general)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxIIM7t27rQ-"
      },
      "source": [
        "## Running tensors on GPUs (and making faster computations)\n",
        "\n",
        "Deep learning algorithms require a lot of numerical operations.\n",
        "\n",
        "And by default these operations are often done on a CPU (computer processing unit).\n",
        "\n",
        "However, there's another common piece of hardware called a GPU (graphics processing unit), which is often much faster at performing the specific types of operations neural networks need (matrix multiplications) than CPUs.\n",
        "\n",
        "Your computer might have one.\n",
        "\n",
        "If so, you should look to use it whenever you can to train neural networks because chances are it'll speed up the training time dramatically.\n",
        "\n",
        "There are a few ways to first get access to a GPU and secondly get PyTorch to use the GPU.\n",
        "\n",
        "> **Note:** When I reference \"GPU\" throughout this course, I'm referencing a [Nvidia GPU with CUDA](https://developer.nvidia.com/cuda-gpus) enabled (CUDA is a computing platform and API that helps allow GPUs be used for general purpose computing & not just graphics) unless otherwise specified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UiR6QpoYQH_"
      },
      "source": [
        "\n",
        "### 1. Getting a GPU\n",
        "\n",
        "You may already know what's going on when I say GPU. But if not, there are a few ways to get access to one.\n",
        "\n",
        "| **Method** | **Difficulty to setup** | **Pros** | **Cons** | **How to setup** |\n",
        "| ----- | ----- | ----- | ----- | ----- |\n",
        "| Google Colab | Easy | Free to use, almost zero setup required, can share work with others as easy as a link | Doesn't save your data outputs, limited compute, subject to timeouts | [Follow the Google Colab Guide](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
        "| Use your own | Medium | Run everything locally on your own machine | GPUs aren't free, require upfront cost | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/locally/) |\n",
        "| Cloud computing (AWS, GCP, Azure) | Medium-Hard | Small upfront cost, access to almost infinite compute | Can get expensive if running continually, takes some time to setup right | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/cloud-partners/) |\n",
        "\n",
        "There are more options for using GPUs but the above three will suffice for now.\n",
        "\n",
        "Personally, I use a combination of Google Colab and my own personal computer for small scale experiments (and creating this course) and go to cloud resources when I need more compute power.\n",
        "\n",
        "> **Resource:** If you're looking to purchase a GPU of your own but not sure what to get, [Tim Dettmers has an excellent guide](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/).\n",
        "\n",
        "To check if you've got access to a Nvidia GPU, you can run `!nvidia-smi` where the `!` (also called bang) means \"run this on the command line\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEMcO-9zYc-w",
        "outputId": "59d901c6-0ca0-4fd1-cd39-23d0d4808b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec 31 12:37:43 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perintah !nvidia-smi digunakan untuk menampilkan informasi tentang perangkat GPU (Graphics Processing Unit) yang terpasang di sistem. Ini umumnya digunakan di lingkungan pengembangan atau komputasi yang menggunakan GPU, seperti ketika Anda menjalankan kode PyTorch atau TensorFlow yang memanfaatkan akselerasi GPU.\n",
        "\n",
        "Berikut adalah penjelasan singkat:\n",
        "\n",
        "!: Tanda seru (!) digunakan di beberapa lingkungan pengembangan (seperti Jupyter Notebook atau Google Colab) untuk menjalankan perintah shell atau sistem operasi.\n",
        "\n",
        "nvidia-smi: Ini adalah perintah sistem operasi untuk menampilkan informasi tentang GPU NVIDIA yang terpasang pada sistem. Informasi ini mencakup detail seperti nama GPU, penggunaan GPU saat ini, suhu, penggunaan memori, dan lainnya.\n",
        "\n",
        "Ketika Anda menjalankan !nvidia-smi, outputnya akan menampilkan tabel yang memberikan gambaran tentang status dan utilitas GPU yang ada di sistem pada saat itu. Informasi ini dapat sangat berguna untuk memantau penggunaan GPU, memastikan bahwa model dan pelatihan Anda berjalan pada perangkat keras yang diinginkan, serta memantau sumber daya yang digunakan."
      ],
      "metadata": {
        "id": "sXkTr6GbMexo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvkB9p5zYf8E"
      },
      "source": [
        "If you don't have a Nvidia GPU accessible, the above will output something like:\n",
        "\n",
        "```\n",
        "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
        "```\n",
        "\n",
        "In that case, go back up and follow the install steps.\n",
        "\n",
        "If you do have a GPU, the line above will output something like:\n",
        "\n",
        "```\n",
        "Wed Jan 19 22:09:08 2022       \n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
        "|                               |                      |                  N/A |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "                                                                               \n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                                  |\n",
        "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "|        ID   ID                                                   Usage      |\n",
        "|=============================================================================|\n",
        "|  No running processes found                                                 |\n",
        "+-----------------------------------------------------------------------------+\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvibZ6e0YcDk"
      },
      "source": [
        "\n",
        "\n",
        "### 2. Getting PyTorch to run on the GPU\n",
        "\n",
        "Once you've got a GPU ready to access, the next step is getting PyTorch to use for storing data (tensors) and computing on data (performing operations on tensors).\n",
        "\n",
        "To do so, you can use the [`torch.cuda`](https://pytorch.org/docs/stable/cuda.html) package.\n",
        "\n",
        "Rather than talk about it, let's try it out.\n",
        "\n",
        "You can test if PyTorch has access to a GPU using [`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OweDLgwjEvZ2",
        "outputId": "45d1507f-d2f9-4fce-f6c5-f46e5cbf77e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# Check for GPU\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menggunakan PyTorch untuk memeriksa apakah sistem memiliki GPU yang tersedia atau tidak. Berikut adalah penjelasan singkat:\n",
        "\n",
        "import torch: Baris ini mengimpor library PyTorch, memungkinkan penggunaan fungsi-fungsi dan struktur data PyTorch.\n",
        "\n",
        "torch.cuda.is_available(): Baris ini memanggil fungsi is_available() dari modul cuda di PyTorch. Fungsi ini mengembalikan nilai boolean (True atau False) yang menunjukkan apakah GPU tersedia atau tidak di sistem saat ini.\n",
        "\n",
        "Jika nilai yang dikembalikan adalah True, itu berarti GPU tersedia dan dapat digunakan untuk akselerasi perhitungan PyTorch. Jika nilai yang dikembalikan adalah False, itu berarti sistem tidak memiliki GPU yang tersedia, dan PyTorch akan menggunakan CPU untuk perhitungan."
      ],
      "metadata": {
        "id": "CC8qXPRdMpm-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jedZcx2PZFpL"
      },
      "source": [
        "If the above outputs `True`, PyTorch can see and use the GPU, if it outputs `False`, it can't see the GPU and in that case, you'll have to go back through the installation steps.\n",
        "\n",
        "Now, let's say you wanted to setup your code so it ran on CPU *or* the GPU if it was available.\n",
        "\n",
        "That way, if you or someone decides to run your code, it'll work regardless of the computing device they're using.\n",
        "\n",
        "Let's create a `device` variable to store what kind of device is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j92HBCKB7rYa",
        "outputId": "7e37605b-2a39-42bf-9a3a-403309862094"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# Set device type\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas mengatur tipe perangkat (device type) yang akan digunakan dalam komputasi PyTorch, berdasarkan ketersediaan GPU di sistem. Berikut adalah penjelasan singkat:\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\": Baris ini menggunakan ekspresi bersyarat (conditional expression) untuk menetapkan nilai ke variabel device. Jika torch.cuda.is_available() mengembalikan True (artinya GPU tersedia), maka device diatur ke string \"cuda\". Jika GPU tidak tersedia, maka device diatur ke string \"cpu\".\n",
        "\n",
        "device: Variabel ini akan berisi tipe perangkat yang akan digunakan dalam komputasi PyTorch, yaitu \"cuda\" jika GPU tersedia, dan \"cpu\" jika tidak.\n",
        "\n",
        "Penggunaan tipe perangkat ini dapat berguna saat membuat tensor atau model PyTorch untuk menentukan apakah perhitungan akan dilakukan pada CPU atau GPU. Misalnya, ketika membuat tensor, Anda dapat menggunakan argumen device=device untuk menetapkan perangkat yang akan digunakan."
      ],
      "metadata": {
        "id": "z-xQUt5HMxzc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjFyPP2WaCch"
      },
      "source": [
        "If the above output `\"cuda\"` it means we can set all of our PyTorch code to use the available CUDA device (a GPU) and if it output `\"cpu\"`, our PyTorch code will stick with the CPU.\n",
        "\n",
        "> **Note:** In PyTorch, it's best practice to write [**device agnostic code**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code). This means code that'll run on CPU (always available) or GPU (if available).\n",
        "\n",
        "If you want to do faster computing you can use a GPU but if you want to do *much* faster computing, you can use multiple GPUs.\n",
        "\n",
        "You can count the number of GPUs PyTorch has access to using [`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MArsn0DFTGfG",
        "outputId": "b8929581-3b9c-4dab-86da-4385788bdaa0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Kode di atas menggunakan PyTorch untuk menghitung jumlah perangkat GPU (Graphics Processing Unit) yang tersedia di sistem. Berikut adalah penjelasan singkat:\n",
        "\n",
        "torch.cuda.device_count(): Baris ini memanggil fungsi device_count() dari modul cuda di PyTorch. Fungsi ini mengembalikan jumlah perangkat GPU yang terdeteksi di sistem.\n",
        "\n",
        "Hasilnya adalah bilangan bulat yang menunjukkan jumlah perangkat GPU yang tersedia. Jika hasilnya adalah 0, itu berarti tidak ada GPU yang terdeteksi, dan PyTorch akan menggunakan CPU secara default. Jika hasilnya lebih besar dari 0, itu menunjukkan jumlah GPU yang tersedia."
      ],
      "metadata": {
        "id": "ovPWN80rM5D-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVNf1hiqa-gO"
      },
      "source": [
        "Knowing the number of GPUs PyTorch has access to is helpful incase you wanted to run a specific process on one GPU and another process on another (PyTorch also has features to let you run a process across *all* GPUs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqQLcuj68OA-"
      },
      "source": [
        "### 3. Putting tensors (and models) on the GPU\n",
        "\n",
        "You can put tensors (and models, we'll see this later) on a specific device by calling [`to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) on them. Where `device` is the target device you'd like the tensor (or model) to go to.\n",
        "\n",
        "Why do this?\n",
        "\n",
        "GPUs offer far faster numerical computing than CPUs do and if a GPU isn't available, because of our **device agnostic code** (see above), it'll run on the CPU.\n",
        "\n",
        "> **Note:** Putting a tensor on GPU using `to(device)` (e.g. `some_tensor.to(device)`) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. To overwrite tensors, reassign them:\n",
        ">\n",
        "> `some_tensor = some_tensor.to(device)`\n",
        "\n",
        "Let's try creating a tensor and putting it on the GPU (if it's available)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhI3srFXEHfP",
        "outputId": "3e917315-cd35-4a2f-9ef4-e37abcb41587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# Create tensor (default on CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas mengilustrasikan cara membuat tensor di PyTorch, menunjukkan perangkat di mana tensor berada, dan bagaimana memindahkan tensor ke GPU jika GPU tersedia. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor = torch.tensor([1, 2, 3]): Baris ini membuat tensor PyTorch dengan nilai [1, 2, 3]. Secara default, tensor akan dibuat di CPU jika tidak ada instruksi khusus untuk menetapkannya ke perangkat lain.\n",
        "\n",
        "print(tensor, tensor.device): Baris ini mencetak atau menampilkan nilai dari tensor dan perangkat tempat tensor tersebut berada. tensor.device memberikan informasi tentang perangkat tempat tensor tersebut disimpan, dan karena tidak ada spesifikasi, tensor akan berada di CPU.\n",
        "\n",
        "tensor_on_gpu = tensor.to(device): Baris ini menggunakan metode .to() untuk memindahkan tensor ke perangkat yang ditentukan. Variabel device sebelumnya diberikan nilai \"cuda\" jika GPU tersedia, atau \"cpu\" jika tidak. Sebagai contoh, jika GPU tersedia, tensor_on_gpu akan menjadi salinan tensor yang berada di GPU.\n",
        "\n",
        "tensor_on_gpu: Hasilnya adalah tensor yang telah dipindahkan ke perangkat yang ditentukan."
      ],
      "metadata": {
        "id": "3uexKodvNLtt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxXeRKO0TGfG"
      },
      "source": [
        "If you have a GPU available, the above code will output something like:\n",
        "\n",
        "```\n",
        "tensor([1, 2, 3]) cpu\n",
        "tensor([1, 2, 3], device='cuda:0')\n",
        "```\n",
        "\n",
        "Notice the second tensor has `device='cuda:0'`, this means it's stored on the 0th GPU available (GPUs are 0 indexed, if two GPUs were available, they'd be `'cuda:0'` and `'cuda:1'` respectively, up to `'cuda:n'`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4puyUX4Bci5D"
      },
      "source": [
        "### 4. Moving tensors back to the CPU\n",
        "\n",
        "What if we wanted to move the tensor back to CPU?\n",
        "\n",
        "For example, you'll want to do this if you want to interact with your tensors with NumPy (NumPy does not leverage the GPU).\n",
        "\n",
        "Let's try using the [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) method on our `tensor_on_gpu`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ChSLJgPTGfG",
        "outputId": "a971d4ad-9ee1-4e52-e3bb-f7546e4140ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3]\n"
          ]
        }
      ],
      "source": [
        "# Contoh tensor di GPU\n",
        "tensor_on_gpu = torch.tensor([1, 2, 3], device='cuda:0')\n",
        "\n",
        "# Memindahkan tensor dari GPU ke CPU\n",
        "tensor_on_cpu = tensor_on_gpu.cpu()\n",
        "\n",
        "# Mengonversi tensor yang berada di CPU menjadi NumPy array\n",
        "numpy_array = tensor_on_cpu.numpy()\n",
        "\n",
        "print(numpy_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
        "tensor_on_gpu.numpy()\n",
        "saat kode akan dirun terjadi error, Error tersebut terjadi karena Anda mencoba mengonversi tensor yang berada di GPU (cuda:0) langsung menjadi NumPy array. Untuk memperbaiki ini, Anda perlu memindahkan tensor dari GPU ke CPU terlebih dahulu, dan baru kemudian mengonversikannya menjadi NumPy array. Dalam contoh di atas, cpu() digunakan untuk memindahkan tensor dari GPU ke CPU, dan setelah itu, Anda dapat menggunakan numpy() untuk mengonversikannya menjadi NumPy array."
      ],
      "metadata": {
        "id": "fshXWmErONyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Kode di atas mengilustrasikan contoh penggunaan PyTorch untuk bekerja dengan tensor di GPU, memindahkan tensor dari GPU ke CPU, dan mengonversi tensor ke NumPy array. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor_on_gpu = torch.tensor([1, 2, 3], device='cuda:0'): Baris ini membuat tensor PyTorch dengan nilai [1, 2, 3] dan menetapkannya ke GPU dengan menyertakan argumen device='cuda:0'. Angka 0 dalam 'cuda:0' merujuk pada nomor identifikasi GPU jika ada lebih dari satu GPU.\n",
        "\n",
        "tensor_on_cpu = tensor_on_gpu.cpu(): Baris ini menggunakan metode .cpu() untuk memindahkan tensor dari GPU ke CPU. Ini berguna jika Anda ingin melanjutkan komputasi di CPU setelah selesai melakukan operasi di GPU.\n",
        "\n",
        "numpy_array = tensor_on_cpu.numpy(): Baris ini menggunakan metode .numpy() untuk mengonversi tensor PyTorch yang berada di CPU menjadi NumPy array. NumPy array dapat digunakan dengan berbagai library dan fungsi-fungsi yang mendukung NumPy.\n",
        "\n",
        "print(numpy_array): Baris ini mencetak atau menampilkan nilai dari NumPy array yang dihasilkan."
      ],
      "metadata": {
        "id": "2cWTOE6vNVbQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhymtkRDTGfG"
      },
      "source": [
        "Instead, to get a tensor back to CPU and usable with NumPy we can use [`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html).\n",
        "\n",
        "This copies the tensor to CPU memory so it's usable with CPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN15s-NdTGfG",
        "outputId": "595975f6-ae22-4937-ddbf-a4dd90b48e18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# Instead, copy the tensor back to cpu\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menunjukkan cara lain untuk mengonversi tensor yang berada di GPU ke NumPy array, tetapi kali ini menggunakan pendekatan yang lebih ringkas dengan menggabungkan pemindahan tensor ke CPU dan konversi ke NumPy array dalam satu baris. Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy(): Baris ini menggunakan metode .cpu() untuk memindahkan tensor dari GPU ke CPU, kemudian langsung menggunakan metode .numpy() untuk mengonversi tensor tersebut ke NumPy array.\n",
        "\n",
        "tensor_back_on_cpu: Hasilnya adalah NumPy array yang dihasilkan."
      ],
      "metadata": {
        "id": "rUVhbkSGNdfs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyzNH5lrTGfH"
      },
      "source": [
        "The above returns a copy of the GPU tensor in CPU memory so the original tensor is still on GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5u83PCRTGfH",
        "outputId": "227f4ca8-9963-4d80-dfd5-2307a04af8a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor_on_gpu adalah sebuah tensor PyTorch yang dibuat dan disimpan di GPU (Graphics Processing Unit). Berikut adalah penjelasan singkat:\n",
        "\n",
        "tensor_on_gpu: Variabel ini adalah tensor PyTorch yang menyimpan nilai [1, 2, 3] dan ditempatkan di GPU. Hal ini dicapai dengan menyertakan argumen device='cuda:0' saat membuat tensor. cuda:0 merujuk pada GPU pertama yang terdeteksi di sistem.\n",
        "tensor_on_gpu digunakan untuk menunjukkan bagaimana membuat tensor di GPU dan kemudian melakukan operasi pada CPU atau mengonversinya ke NumPy array jika diperlukan. Variabel semacam ini penting dalam pengembangan dengan PyTorch, terutama ketika bekerja dengan perangkat keras akselerasi seperti GPU untuk meningkatkan kecepatan perhitungan."
      ],
      "metadata": {
        "id": "pDzjWLQ-NngA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlmBpnuPTGfH"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "All of the exercises are focused on practicing the code above.\n",
        "\n",
        "You should be able to complete them by referencing each section or by following the resource(s) linked.\n",
        "\n",
        "**Resources:**\n",
        "\n",
        "* [Exercise template notebook for 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb).\n",
        "* [Example solutions notebook for 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/00_pytorch_fundamentals_exercise_solutions.ipynb) (try the exercises *before* looking at this).\n",
        "\n",
        "1. Documentation reading - A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness). See the documentation on [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor) and for [`torch.cuda`](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics).\n",
        "2. Create a random tensor with shape `(7, 7)`.\n",
        "3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape `(1, 7)` (hint: you may have to transpose the second tensor).\n",
        "4. Set the random seed to `0` and do exercises 2 & 3 over again.\n",
        "5. Speaking of random seeds, we saw how to set it with `torch.manual_seed()` but is there a GPU equivalent? (hint: you'll need to look into the documentation for `torch.cuda` for this one). If there is, set the GPU random seed to `1234`.\n",
        "6. Create two random tensors of shape `(2, 3)` and send them both to the GPU (you'll need access to a GPU for this). Set `torch.manual_seed(1234)` when creating the tensors (this doesn't have to be the GPU random seed).\n",
        "7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\n",
        "8. Find the maximum and minimum values of the output of 7.\n",
        "9. Find the maximum and minimum index values of the output of 7.\n",
        "10. Make a random tensor with shape `(1, 1, 1, 10)` and then create a new tensor with all the `1` dimensions removed to be left with a tensor of shape `(10)`. Set the seed to `7` when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Exercise 1\n",
        "random_tensor = torch.rand((7, 7))\n",
        "print(\"Exercise 1 - Random Tensor:\")\n",
        "print(random_tensor)\n",
        "\n",
        "# Exercise 2\n",
        "another_random_tensor = torch.rand((1, 7))\n",
        "result_tensor = torch.mm(random_tensor, another_random_tensor.t())\n",
        "print(\"\\nExercise 2 - Matrix Multiplication:\")\n",
        "print(result_tensor)\n",
        "\n",
        "# Exercise 3\n",
        "torch.manual_seed(0)\n",
        "random_tensor = torch.rand((7, 7))\n",
        "another_random_tensor = torch.rand((1, 7))\n",
        "result_tensor = torch.mm(random_tensor, another_random_tensor.t())\n",
        "print(\"\\nExercise 3 - Matrix Multiplication with Seed 0:\")\n",
        "print(result_tensor)\n",
        "\n",
        "# Exercise 4\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(1234)\n",
        "\n",
        "# Exercise 5\n",
        "random_tensor_gpu_1 = torch.rand((2, 3), device='cuda')\n",
        "random_tensor_gpu_2 = torch.rand((2, 3), device='cuda')\n",
        "result_tensor_gpu = torch.mm(random_tensor_gpu_1, random_tensor_gpu_2.t())\n",
        "print(\"\\nExercise 5 - Matrix Multiplication on GPU:\")\n",
        "print(result_tensor_gpu)\n",
        "\n",
        "# Exercise 6\n",
        "max_value = torch.max(result_tensor_gpu)\n",
        "min_value = torch.min(result_tensor_gpu)\n",
        "print(\"\\nExercise 6 - Max and Min Values:\")\n",
        "print(\"Max Value:\", max_value.item())\n",
        "print(\"Min Value:\", min_value.item())\n",
        "\n",
        "# Exercise 7\n",
        "max_index = torch.argmax(result_tensor_gpu)\n",
        "min_index = torch.argmin(result_tensor_gpu)\n",
        "print(\"\\nExercise 7 - Max and Min Index Values:\")\n",
        "print(\"Max Index:\", max_index.item())\n",
        "print(\"Min Index:\", min_index.item())\n",
        "\n",
        "# Exercise 8\n",
        "torch.manual_seed(7)\n",
        "random_tensor_4d = torch.rand((1, 1, 1, 10))\n",
        "flattened_tensor = random_tensor_4d.squeeze()\n",
        "print(\"\\nExercise 8 - Flattened Tensor:\")\n",
        "print(\"Original Tensor Shape:\", random_tensor_4d.shape)\n",
        "print(\"Flattened Tensor:\", flattened_tensor)\n",
        "print(\"Flattened Tensor Shape:\", flattened_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrG43IqGOz8G",
        "outputId": "68b5abeb-35c5-4446-cb00-174557933c7b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exercise 1 - Random Tensor:\n",
            "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901],\n",
            "        [0.8964, 0.4556, 0.6323, 0.3489, 0.4017, 0.0223, 0.1689],\n",
            "        [0.2939, 0.5185, 0.6977, 0.8000, 0.1610, 0.2823, 0.6816],\n",
            "        [0.9152, 0.3971, 0.8742, 0.4194, 0.5529, 0.9527, 0.0362],\n",
            "        [0.1852, 0.3734, 0.3051, 0.9320, 0.1759, 0.2698, 0.1507],\n",
            "        [0.0317, 0.2081, 0.9298, 0.7231, 0.7423, 0.5263, 0.2437],\n",
            "        [0.5846, 0.0332, 0.1387, 0.2422, 0.8155, 0.7932, 0.2783]])\n",
            "\n",
            "Exercise 2 - Matrix Multiplication:\n",
            "tensor([[1.8542],\n",
            "        [1.9611],\n",
            "        [2.2884],\n",
            "        [3.0481],\n",
            "        [1.7067],\n",
            "        [2.5290],\n",
            "        [1.7989]])\n",
            "\n",
            "Exercise 3 - Matrix Multiplication with Seed 0:\n",
            "tensor([[1.8542],\n",
            "        [1.9611],\n",
            "        [2.2884],\n",
            "        [3.0481],\n",
            "        [1.7067],\n",
            "        [2.5290],\n",
            "        [1.7989]])\n",
            "\n",
            "Exercise 5 - Matrix Multiplication on GPU:\n",
            "tensor([[0.2786, 0.7668],\n",
            "        [0.7343, 0.6102]], device='cuda:0')\n",
            "\n",
            "Exercise 6 - Max and Min Values:\n",
            "Max Value: 0.7667766809463501\n",
            "Min Value: 0.27863210439682007\n",
            "\n",
            "Exercise 7 - Max and Min Index Values:\n",
            "Max Index: 1\n",
            "Min Index: 0\n",
            "\n",
            "Exercise 8 - Flattened Tensor:\n",
            "Original Tensor Shape: torch.Size([1, 1, 1, 10])\n",
            "Flattened Tensor: tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
            "        0.8513])\n",
            "Flattened Tensor Shape: torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9zAfVfy2nFD"
      },
      "source": [
        "## Extra-curriculum\n",
        "\n",
        "* Spend 1-hour going through the [PyTorch basics tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html) (I'd recommend the [Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) and [Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html) sections).\n",
        "* To learn more on how a tensor can represent data, see this video: [What's a tensor?](https://youtu.be/f5liqUk0ZTw)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
